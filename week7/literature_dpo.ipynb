{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-QI_eCrOoku"
   },
   "source": [
    "# 기본적인 세팅\n",
    "\n",
    "1. gemma3:1b 허깅페이스에서 라이선스 동의를 받아놓아야 함\n",
    "\n",
    "2. 허깅페이스 api key를 아래에 입력해야 함\n",
    "\n",
    "3. corpus.json을 업로드 해놓아야 함\n",
    "\n",
    "4. A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORMnQF8RttKr",
    "outputId": "c6a834e1-49ac-463f-85ad-d3e851331169"
   },
   "outputs": [],
   "source": [
    "!pip install trl huggingface_hub loguru -q\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGPX6-3mtvG-",
    "outputId": "925920ee-6ba7-47fa-e28b-440dcb5113f3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from loguru import logger\n",
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import platform\n",
    "\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sys.stdout,\n",
    "    level=\"INFO\",\n",
    "    colorize=True,\n",
    "    format=\"<green>{time:HH:mm:ss}</green> | <level>{level: <5}</level> | {message}\"\n",
    ")\n",
    "\n",
    "# 버전 로깅\n",
    "logger.info(f\"python version       : {platform.python_version()}\")\n",
    "logger.info(f\"torch version        : {torch.__version__}\")\n",
    "logger.info(f\"transformers version : {__import__('transformers').__version__}\")\n",
    "logger.info(f\"datasets version     : {__import__('datasets').__version__}\")\n",
    "logger.info(f\"trl version          : {__import__('trl').__version__}\")\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "def load_raw_data(path=\"/content/corpus.json\"):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# DPO용 전처리 함수\n",
    "def make_dpo_data(raw_data):\n",
    "    result = []\n",
    "    for item in raw_data:\n",
    "        instruction = item[\"instruction\"]\n",
    "        keywords    = item[\"input\"]\n",
    "        prompt      = f\"{instruction}: {', '.join(keywords)}\"\n",
    "        chosen      = item[\"chosen\"]\n",
    "        rejected    = item[\"rejected\"]\n",
    "\n",
    "        result.append({\n",
    "            \"prompt\":   prompt,\n",
    "            \"chosen\":   chosen,\n",
    "            \"rejected\": rejected\n",
    "        })\n",
    "    return result\n",
    "\n",
    "def test(prompt, model, tokenizer, necessary_word):\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "    # 토크나이즈\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # 생성\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # 디코딩\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    logger.info(\"=\"*100)\n",
    "    logger.info(necessary_word + \"\\n\" + prompt)\n",
    "    logger.info(necessary_word + \"\\n\" + generated_text)\n",
    "    logger.info(\"=\"*100)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "4f828a200f7a429695401546aa015f29",
      "f4e631601c714d768521249ecb84d481",
      "4cfcc6b51f69426888d72d249cae4975",
      "289b191759994610abaee4bebadbdc1f",
      "e8b9029f45d849108e7e346dfdda83c2",
      "37aff901a57342b48f05055fa2cc1f28",
      "9d92e34bbf5a4058993fbc148cace151",
      "691fa68df96e4cc78b429abbf84fc278",
      "19da4553acac4c1a95dcad1b71f664df",
      "2843a05de87b4f6caafcacaf7db13cd7",
      "a73192b969df4a58bc7193234d9875dc",
      "80d063be96944c739d73a64ee2cc4ca7",
      "4fba71a994f64508bb5d6975fc8c8428",
      "46492645081b42d6bca972c2f2aae649",
      "bff06a2e19d54a3c9754d2076133ff80",
      "0e2630b351d0429eb10ed7dbc5f3bf78",
      "113051dc50e34efbb40f4bc23d677c37",
      "3dec6b29b7c242ad9d43fc115e6a1431",
      "d13e3389e1a34f2893e6702bd8cd5f25",
      "6b73f9cd6d424fbca82e215eff63f3a1",
      "f211c8b6764741a1ad07524d42b9ae12",
      "42d1d28f0e5140999114c4c23f231d72",
      "0b54bf785eda41fd91328d80f6719977",
      "f5ca4b05d12648a4ab1f0cc426454198",
      "7355e70baa5543c9bda9ff0b9501286d",
      "61b68bbedf1f4857a83580fc7195d4f9",
      "fa49937f20ce4d5c9816419f6575a2a1",
      "99812bc826fc447da5d286e98f2b5a44",
      "2b572319dd8346a79d948eb3fdeb9249",
      "911756cee93f47cfa032eea7446ed3ad",
      "f8a564c8d45346db9194922d9a232a07",
      "daea00d3a47547a894cc2576fb7490fd",
      "e3403ab4f9b34196a2b2f2593d9ce240",
      "8c704c70a301423eb4104d62d23fa350",
      "daa2e54f11f04b76bde89e1321998dce",
      "c4fefacfb4af422cae90fa1dadb5aabb",
      "ab446d71de9e4ad3b0a1da7d5270573e",
      "3f139975a8684c8482ee5b8608f9084d",
      "9f5a4fc500fd4032b2a87cf10fe16f9d",
      "2cf05a42aa0d4a7fbf08eda29ca2391a",
      "f4086371b3304f4d92fee6bdd8f43baf",
      "bc024f36c600484b91fcc8c015b808ce",
      "0c292d557f9440799ed93185b375efe1",
      "ce868b9cb34b47a3a8d4a6ba048497fd",
      "69336a5f5b8642b5ba7c908005f97e47",
      "6678948e30c740feaa0b57a621a170d2",
      "a7a8651899254fb6a520dd16fa13c2ce",
      "78ba5f639b3b4c87bf4451d8c1ca4cc6",
      "bb8db7537e1244e2bef8b1ee4a2b69a2",
      "ede016bbf2584eee840607ecb07d8537",
      "5b63a14130bd475ea9a2d8e63052367b",
      "72c9f71e6c184fa3a4e9489e8420188b",
      "9e8a884a3c994abe85a8b2e1144a9ce3",
      "5bb507e9dc4b4d269701379609dcde40",
      "21952a8ffc54465fb64f6a38d50868fa",
      "f3a42ca6d5e2446f83d551833dcbfa39",
      "49e1bbb4e4964fb18b19f393ed56fa55",
      "fd4b0431486c4e25af257b34d379aef9",
      "e662c06b06834b05b5aa88da77ca9982",
      "8fd2adba16344b528842afa94a1bd739",
      "5033cd8d217642a7b66b90637c6db1e8",
      "e31c803c99e441d195afcd02e7517836",
      "a65a2c35b6944720aa683bbc54c4e416",
      "6216d60a26af4712b8b2b65b01b7673c",
      "cc14ea6b1cd74f97a7cf1a989c1f8432",
      "1181243b68e249878e5e6e8adbc6ee9d"
     ]
    },
    "id": "51Y5opVLtxEj",
    "outputId": "31a43f21-92d1-455b-d7c0-794671e002e3"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "save_total_limit = 2\n",
    "output_dir = \"./outputs/dpo\"\n",
    "logging_dir = \"./outputs/logs\"\n",
    "dpo_dir = \"./outputs/best_dpo\"\n",
    "\n",
    "# 모델 및 토크나이저 설정\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCdonJ-4Mda9",
    "outputId": "f9101f86-2547-4a66-e8ab-9616c7b5bbcd"
   },
   "outputs": [],
   "source": [
    "# 문학적 instruction 목록\n",
    "instructions = [\n",
    "    \"제공된 단어로 문학적인 어조로 짧은 장면을 창작해주세요.\",\n",
    "    \"아래 단어들을 활용해 상징과 감정이 담긴 문학적 단편을 작성해주세요.\",\n",
    "    \"다음 키워드를 사용해 감성적이고 은유적인 이야기를 작성해주세요.\",\n",
    "    \"아래 키워드를 사용해 비유와 상징이 녹아든 문학적 장면을 묘사해주세요.\"\n",
    "]\n",
    "\n",
    "# 키워드 목록\n",
    "keywords_list = [\n",
    "    [\"밥\", \"숟가락\", \"그릇\"],\n",
    "    [\"창문\", \"바람\", \"햇살\"],\n",
    "    [\"우산\", \"비\", \"골목\"],\n",
    "    [\"신발\", \"거리\", \"그림자\"],\n",
    "    [\"책상\", \"연필\", \"종이\"],\n",
    "    [\"시계\", \"벽\", \"침묵\"],\n",
    "    [\"의자\", \"창가\", \"오후\"],\n",
    "    [\"커피\", \"잔\", \"향기\"],\n",
    "    [\"손\", \"온기\", \"기억\"],\n",
    "    [\"길\", \"노을\", \"발자국\"]\n",
    "]\n",
    "\n",
    "# 데카르트 곱을 이용해 모든 instruction-keywords 조합 생성\n",
    "test_prompts = [\n",
    "    f\"{instruction} {', '.join(keywords)}\"\n",
    "    for instruction, keywords in itertools.product(instructions, keywords_list)\n",
    "]\n",
    "\n",
    "necessary_word = \"[Before Train]\"\n",
    "\n",
    "before_response = []\n",
    "for prompt in test_prompts:\n",
    "    before_response.append(test(prompt, model, tokenizer, necessary_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQU43Hg2tz04",
    "outputId": "9204ea91-a0ef-4535-e9ed-90764644bb7a"
   },
   "outputs": [],
   "source": [
    "# pad_token 설정\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    logger.info(f\"[Tokenizer] pad_token was None. Set to eos_token: {tokenizer.pad_token}\")\n",
    "else:\n",
    "    logger.info(f\"[Tokenizer] pad_token already set: {tokenizer.pad_token}\")\n",
    "\n",
    "# 데이터 전처리 및 분할\n",
    "raw_data   = load_raw_data()\n",
    "dpo_data   = make_dpo_data(raw_data)\n",
    "dataset    = Dataset.from_list(dpo_data)\n",
    "split      = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split[\"train\"]\n",
    "eval_dataset  = split[\"test\"]\n",
    "\n",
    "logger.info(f\"[Raw Data] First sample:\\n{json.dumps(raw_data[0], ensure_ascii=False, indent=2)}\")\n",
    "logger.info(f\"[DPO Records] First record:\\n{json.dumps(dpo_data[0], ensure_ascii=False, indent=2)}\")\n",
    "logger.info(f\"[Dataset] Total samples: {len(dataset)}\")\n",
    "logger.info(f\"[Split] Train size: {len(train_dataset)}, Eval size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuPwr8o-t1tc",
    "outputId": "4ed46367-8d2e-48ff-ef3f-e25e45a10adc"
   },
   "outputs": [],
   "source": [
    "# 총 step 계산\n",
    "total_train_steps = len(train_dataset) // batch_size * num_epochs\n",
    "logging_steps     = max(1, total_train_steps // (num_epochs * 2))\n",
    "save_steps        = logging_steps\n",
    "\n",
    "logger.info(f\"Total samples (train): {len(train_dataset)}\")\n",
    "logger.info(f\"Total samples (eval): {len(eval_dataset)}\")\n",
    "logger.info(f\"Batch size: {batch_size}\")\n",
    "logger.info(f\"Epochs: {num_epochs}\")\n",
    "logger.info(f\"Total training steps: {total_train_steps}\")\n",
    "logger.info(f\"Logging steps: {logging_steps}\")\n",
    "logger.info(f\"Save steps: {save_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685,
     "referenced_widgets": [
      "442b9f0bc20c4febb0c757221d6ac429",
      "13b6a492517e49c6819e54a60a749157",
      "44c8ac19c5ca48a4bb720976b4a61990",
      "e354145887444c81b992a243988e5fbe",
      "3009081755914bc69b7b623fb6b62a4b",
      "bd06b32a53b84eb2a7e4a2a3f6b64ba9",
      "4b41c1a145ae4ce8ae9f59eaa88be976",
      "baf59e8881ab487db53754b1dfc3cdee",
      "8e30582a4f3b4a7aaeee003eddffa371",
      "6be19414ce484e9e9f2b3f4e7dcba396",
      "8e1072958814498c83bb610df956ac96",
      "a41b42f35eab486597a7e089180e9c32",
      "29ea2a81dc054673b3db756da48965b1",
      "e467b4b8c13d4c65a6c23b58b1f2d141",
      "f5accde1dc8b43c19b8c34dafbfcb2d1",
      "f178a9a762f341229f442192992e598d",
      "1edcbe5ed6e945ca8bcbd23a2eae096f",
      "24d8f7f4ea0549b2a0e0467e3cc496c0",
      "c1f6df612d3049418f7fb4d020833ee6",
      "d97aa08d134743279d931743703ea3b3",
      "0d7913d10d7047c99246dcf8bd31f365",
      "6b7bbf4c152a4d28b7923057f34a2204",
      "8778b641ab5a4d3ba20a174692c8ca4e",
      "26779e5376b640b0964a2112539789ee",
      "80c04b85475d4038a6524f6dc13a7bf7",
      "8d7f52c1d4744c44a684158cad8ff4c7",
      "2c3780074a71408e867d055731402ef1",
      "7b47e7dea7c54a82a3b4514751926750",
      "4c64fc3f23914a3988cfd12f984bb7fb",
      "ae60443f335a4aa3baaaca75f7c14b5d",
      "d5da8562589c4a60a010efab8dcea1ee",
      "001254f98e7d4c729a52a43cbd64ba9d",
      "c0e06e3dd7394744b97dbea657182ea0",
      "28dc6451ee024693886efe3455d92631",
      "3432392ec6334eb692e837ad007089cb",
      "8f9eb69d1e534148be29799279b86ac4",
      "6682465c1fc14a73aad0c016fdfae6dd",
      "baff800826b746168f9df8c40bd1412e",
      "a69076f29f7d4afd80fbcefe11301170",
      "5bed3bc87c3542a9af6e52725b57f9fc",
      "3f923af8ef4144e09767cb18c45f9d52",
      "966c9cb22f3942eb864ed914703b3336",
      "d0b1770827a14d338177ed13c264ad86",
      "58f2a4122c9d4ca6a5f9242df7e337ab",
      "c6372aacb10344538c53893f8c7dcdb6",
      "c6a0b23787b24c25842f27faf0dde98b",
      "c7f6e32f3c0142669d759f2e8054a66d",
      "e33b0dd738a74099aeecb3bcaa19aa7c",
      "4bcaea5c3bd64c39a8332d9a230c1159",
      "1f45b6ddd78142a5bbc37a08783ddba3",
      "b0e93856111e4ccb8ec0aea517bccf28",
      "62e748a1b4784ccb8be8d70e4c70654a",
      "56ecb8de68f84474a08372072a492e78",
      "74f7aa73b2cd4ae591f78e94f470ea16",
      "5cfcf33a322b4585af513b62244fc548",
      "c1ce2ac1aa5441edb9e756450bd1d6a3",
      "6f4bd898c1424aea8f026e302da9b4eb",
      "e0c9a9a4ecf1439982c48a539c3600a0",
      "103d16a57a154a8e871f51324e997f96",
      "96d9e6706ef34b82a3360c7762c8096c",
      "10f356e507c24788a2a77dd7ff442e95",
      "5d4deaf270f446f5b67105f69e511877",
      "1588c9e8d23d44309f9d2c4c98170bb7",
      "1fd8ce0a941b4b6c8f40202c52c3c69f",
      "29004151b940477b91f07e670df37d07",
      "658c9822a55543c58a68a6b4bf18b59e"
     ]
    },
    "id": "V8b6QcD3t3qZ",
    "outputId": "e3099296-ee45-4623-e597-1b9ec87cc40c"
   },
   "outputs": [],
   "source": [
    "# DPOConfig\n",
    "training_args = DPOConfig(\n",
    "    beta=0.1,\n",
    "    max_length=512,\n",
    "    max_prompt_length=192,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_dir=logging_dir,\n",
    "    logging_steps=logging_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=save_steps,\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=logging_steps,\n",
    "    save_total_limit=save_total_limit,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Trainer 정의\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "trainer.model.save_pretrained(dpo_dir)\n",
    "tokenizer.save_pretrained(dpo_dir)\n",
    "shutil.make_archive(\"best_dpo\", 'zip', dpo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zoe9xTljuavw",
    "outputId": "968524d6-3045-43a7-db0f-bef6af741915"
   },
   "outputs": [],
   "source": [
    "total_size = sum(os.path.getsize(os.path.join(root, f))\n",
    "                 for root, _, files in os.walk(dpo_dir)\n",
    "                 for f in files)\n",
    "\n",
    "logger.info(f\"Total size of best_dpo: {total_size / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuW1S1kp_OA5",
    "outputId": "5853406c-c880-4229-95eb-e9feb3460a3f"
   },
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    f\"{instruction} {', '.join(keywords)}\"\n",
    "    for instruction, keywords in itertools.product(instructions, keywords_list)\n",
    "]\n",
    "\n",
    "necessary_word = \"[After Train]\"\n",
    "\n",
    "after_response = []\n",
    "for prompt in test_prompts:\n",
    "    after_response.append(test(prompt, model, tokenizer, necessary_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1i3NBn4Hx7J"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
