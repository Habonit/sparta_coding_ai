{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBR_tHdKPtXl"
   },
   "source": [
    "# 기본적인 세팅\n",
    "\n",
    "1. gemma3:1b 허깅페이스에서 라이선스 동의를 받아놓아야 함\n",
    "\n",
    "2. 허깅페이스 api key를 아래에 입력해야 함\n",
    "\n",
    "3. corpus.json을 업로드 해놓아야 함\n",
    "\n",
    "4. A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Tul2dVKBelJ",
    "outputId": "0dcc2b95-4aed-484f-a42f-5423903abf66"
   },
   "outputs": [],
   "source": [
    "!pip install trl huggingface_hub loguru -q\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEcQIUPGoZ08",
    "outputId": "609ee950-7f32-416d-834a-d3575c6bdd22"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments\n",
    ")\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from loguru import logger\n",
    "import shutil\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import platform\n",
    "\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sys.stdout,\n",
    "    level=\"INFO\",\n",
    "    colorize=True,\n",
    "    format=\"<green>{time:HH:mm:ss}</green> | <level>{level: <5}</level> | {message}\"\n",
    ")\n",
    "\n",
    "# 버전 로깅\n",
    "logger.info(f\"python version       : {platform.python_version()}\")\n",
    "logger.info(f\"torch version        : {torch.__version__}\")\n",
    "logger.info(f\"transformers version : {__import__('transformers').__version__}\")\n",
    "logger.info(f\"datasets version     : {__import__('datasets').__version__}\")\n",
    "logger.info(f\"trl version          : {__import__('trl').__version__}\")\n",
    "\n",
    "# 데이터 로드\n",
    "def load_raw_data(path=\"/content/corpus.json\"):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 데이터 전처리\n",
    "def make_sft_data(raw_data):\n",
    "    result = []\n",
    "    for item in raw_data:\n",
    "        instruction = item['instruction']\n",
    "        keywords = item['input']\n",
    "        prompt = f\"{instruction}: {', '.join(keywords)}\"\n",
    "        chosen = item['chosen']\n",
    "        result.append({\n",
    "            'input': prompt,\n",
    "            'target': chosen\n",
    "        })\n",
    "    return result\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess(example):\n",
    "    input_enc = tokenizer(example[\"input\"], truncation=True, max_length=192)\n",
    "    target_enc = tokenizer(example[\"target\"], truncation=True, max_length=192)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_enc[\"input_ids\"],\n",
    "        \"attention_mask\": input_enc[\"attention_mask\"],\n",
    "        \"labels\": target_enc[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "def test(prompt, model, tokenizer, necessary_word):\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "    # 토크나이즈\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # 생성\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # 디코딩\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    logger.info(\"=\"*100)\n",
    "    logger.info(necessary_word + \"\\n\" + prompt)\n",
    "    logger.info(necessary_word + \"\\n\" + generated_text)\n",
    "    logger.info(\"=\"*100)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "781f3c3b915d4abebceb82f56fdcb377",
      "e6501082f9f24b3b9bb0b165575c89d5",
      "d1de313d16fd4a5d919d5e01a11d03e2",
      "5301b46e95604ef1bd723b61cb195c61",
      "07e8e694ba264d1bb98de4bbf4582988",
      "26aadc7a454b4ca4b01b7524582af0fd",
      "4d5879678c474cf5961a63e62aa49d33",
      "1e38439f780747a0a34dcc92c5a88ee1",
      "98fca8da93be49c59d38c843b3a63dfb",
      "791c8424c8934a6eb0475d67772af3dc",
      "6e26ac2c8ba64cad8f149d51caa58e18",
      "532f9d07535348968ef252fc099f193c",
      "265b80df575c4eaab37659c6d48f4bcb",
      "683cf6efe3c749b1beef5a97839d8159",
      "58856d24120548d7883b2fdca43967bd",
      "30908e8984b74b4fb758fd75cdfd009b",
      "5e979d582bd64d7eb6f270a7e1273c3c",
      "600fabf36dd34fd4a3d41871ad178787",
      "19cc82db962c4e1eb2a2caf94f736644",
      "a8c7f7d0cacb4a04be214c6c5a21500c",
      "ce0302abc9f64a75959437b1a47f62a2",
      "93bbc58900bf40049ab2c81a9cd2580b",
      "d5841f73f584487a88eeae5951bce631",
      "b0b5b833a3bf470eae2ec161ad28a778",
      "6737fd6c4633408dbe2e69b14bf3d8dd",
      "697d97fa7a1d43b29e166d3d315fabaa",
      "967f2b0301b548189d398fb210a73e7b",
      "c4e78f1750884a838d0fceac3e5bd566",
      "ce77ba819cfb4145963e45b2d063f6a8",
      "36cc841a3de246fabaf02b97857b80b3",
      "67fe0cea68fa45f180226c1a02d48074",
      "aeabda5000824ceabeede0652381e3f2",
      "567043a36f4344a4b37e7cfcf30a204d",
      "4820e0ee435245bcab81acfdce169231",
      "c667a61663ea49f5abbf447907916695",
      "ee13e24db789471191b74b1bcb0df3f2",
      "697bfd5d05844b98a60af91e9bc8fbdc",
      "bcd2ab4e94744a9f893b25f4555f2089",
      "10921d9cdce94913b721bcbac54d3d1a",
      "a73d0186d9bb4893a542eb45d09a720b",
      "d597229ac3cf4dcdb12fd0a7c75db5de",
      "ed04fa4570f0422d9b75c82e18b0d574",
      "028899a8d27d4d319ed05b7a39a86be4",
      "2e0d32a6e5ec4b33bdb8c12e811cf682",
      "8778c3851cf84473bc720418dac2c59b",
      "ddcc0628383e4abfab4ddb490cdaba10",
      "4757ac4a47e44be3973dcbdf21ea8e52",
      "69774695e69a43d283e5928f020838f3",
      "b893389b1cd9428c9538bf66ad88fe4d",
      "2213b5a724df42c393a53748d35a8c46",
      "cd56b10df49b46639202e27be320bb21",
      "4ddd2bfcb4e840f88e4bad603361473c",
      "51f9725df73642deacc66cba8c86ea0e",
      "9bdf20a259574e56a575537cf6a4721a",
      "e96577e3bb3240a581765bd3446b4c08",
      "fc793debfcdb47bdb26157b169501330",
      "ba0dcbf8e40347d3a4d7b5650605de77",
      "42e9cc517073477cb3a4f384e3813bae",
      "86d8e32b29814f2b9750c30550ceae15",
      "959c4c6b7db9482baa7257741c3a8ed7",
      "1f4b938c46f940bf88ed699298cc6b3b",
      "85e625ee1c2e491db1f85be689a5a196",
      "08afe622f4db424e9d9733122a2fb241",
      "25f444fc6b8140a980681c9c408a2d85",
      "e8d21575c6fe4b5d95263989c9466a26",
      "7d261c1c0fde481aa17d3b4e4ccf15f0"
     ]
    },
    "id": "FNQFpQUtodfs",
    "outputId": "8429dadd-ec1f-4483-9c16-7be033961102"
   },
   "outputs": [],
   "source": [
    "# 훈련 파라미터\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "save_total_limit = 2\n",
    "output_dir = \"./outputs/sft\"\n",
    "logging_dir = \"./outputs/logs\"\n",
    "sft_dir = \"./outputs/best_sft\"\n",
    "\n",
    "# 모델 및 토크나이저 설정\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IHgYdDVMDbu",
    "outputId": "0c956221-2be3-41d8-96d3-5d55d363e1c6"
   },
   "outputs": [],
   "source": [
    "# 문학적 instruction 목록\n",
    "instructions = [\n",
    "    \"제공된 단어로 문학적인 어조로 짧은 장면을 창작해주세요.\",\n",
    "    \"아래 단어들을 활용해 상징과 감정이 담긴 문학적 단편을 작성해주세요.\",\n",
    "    \"다음 키워드를 사용해 감성적이고 은유적인 이야기를 작성해주세요.\",\n",
    "    \"아래 키워드를 사용해 비유와 상징이 녹아든 문학적 장면을 묘사해주세요.\"\n",
    "]\n",
    "\n",
    "# 키워드 목록\n",
    "keywords_list = [\n",
    "    [\"밥\", \"숟가락\", \"그릇\"],\n",
    "    [\"창문\", \"바람\", \"햇살\"],\n",
    "    [\"우산\", \"비\", \"골목\"],\n",
    "    [\"신발\", \"거리\", \"그림자\"],\n",
    "    [\"책상\", \"연필\", \"종이\"],\n",
    "    [\"시계\", \"벽\", \"침묵\"],\n",
    "    [\"의자\", \"창가\", \"오후\"],\n",
    "    [\"커피\", \"잔\", \"향기\"],\n",
    "    [\"손\", \"온기\", \"기억\"],\n",
    "    [\"길\", \"노을\", \"발자국\"]\n",
    "]\n",
    "\n",
    "necessary_word = \"[Before Train]\"\n",
    "\n",
    "# 데카르트 곱을 이용해 모든 instruction-keywords 조합 생성\n",
    "test_prompts = [\n",
    "    f\"{instruction} {', '.join(keywords)}\"\n",
    "    for instruction, keywords in itertools.product(instructions, keywords_list)\n",
    "]\n",
    "\n",
    "before_response = []\n",
    "for prompt in test_prompts:\n",
    "    before_response.append(test(prompt, model, tokenizer, necessary_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466,
     "referenced_widgets": [
      "013fb183b55a4301bf456eb5075a9fe4",
      "532a2719a67c4a8b80750c35757a3601",
      "3812e43f352e448aa510269338e06af0",
      "5884d2b86a974882be811a5e4516e22f",
      "f92610d990984678b58edc5ff7e69697",
      "d537fecf54c9440380c87dc0dada90a4",
      "656945637ead45e881de8c678b9de75e",
      "9fe4d73b5b984c35973096a550836b5d",
      "bfe0f2820dd2407b907442e3a3873cdf",
      "42c9b3e4c1dc42f187306866a2c4fe93",
      "8a9d44f5d72d4dc687f8e898e5ea2669",
      "6e7e283a990940dbbea0a09ca893269f",
      "2be7ce151fea426bb52ddba94cec9abe",
      "f6c930e04d264ab39d1bdd25d9e48bc1",
      "3e316b2f66ee40af82cd20bc32ed5c46",
      "681296670ecf46cb82bc6d9719bfdfc4",
      "c7cbe324bc5e477ba7060c5e3cfdfeac",
      "fa6be60f0b9343f28db8ae6622dd433e",
      "cdc9c35cba22452a921b7fcef393bc1d",
      "6ba0f1ceb97145a191eadac6f7d2656a",
      "2b1d3e2b245440feb49904b2ca01501b",
      "219e096ea51e414191d9bcfc9b8b4f86"
     ]
    },
    "id": "-kJWhfUIoio1",
    "outputId": "c7327117-1111-431a-d893-3686434f15fb"
   },
   "outputs": [],
   "source": [
    "# pad_token 설정 및 로그\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    logger.info(f\"[Tokenizer] pad_token was None. Set to eos_token: {tokenizer.pad_token}\")\n",
    "else:\n",
    "    logger.info(f\"[Tokenizer] pad_token already set: {tokenizer.pad_token}\")\n",
    "\n",
    "# 데이터 준비 및 분할\n",
    "raw_data = load_raw_data()\n",
    "sft_records = make_sft_data(raw_data)\n",
    "dataset = Dataset.from_list(sft_records)\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"].map(preprocess, remove_columns=[\"input\", \"target\"])\n",
    "eval_dataset = split_dataset[\"test\"].map(preprocess, remove_columns=[\"input\", \"target\"])\n",
    "\n",
    "\n",
    "logger.info(f\"[Raw Data] First sample:\\n{json.dumps(raw_data[0], ensure_ascii=False, indent=2)}\")\n",
    "logger.info(f\"[SFT Records] First record:\\n{json.dumps(sft_records[0], ensure_ascii=False, indent=2)}\")\n",
    "logger.info(f\"[Dataset] Total samples: {len(dataset)}\")\n",
    "logger.info(f\"[Split] Train size: {len(split_dataset['train'])}, Eval size: {len(split_dataset['test'])}\")\n",
    "logger.info(f\"[Train Preprocessed] Sample keys: {list(train_dataset[0].keys())}\")\n",
    "logger.info(f\"[Train Preprocessed] input_ids length: {len(train_dataset[0]['input_ids'])}, labels length: {len(train_dataset[0]['labels'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSrb0rOnofyL",
    "outputId": "b1f87637-87f7-4353-c05f-21fab96980a6"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 정의\n",
    "\n",
    "total_train_steps = len(train_dataset) // batch_size * num_epochs\n",
    "logging_steps = max(1, total_train_steps // (num_epochs * 2))\n",
    "save_steps = logging_steps\n",
    "\n",
    "# 로깅 출력\n",
    "logger.info(f\"Total samples (train): {len(train_dataset)}\")\n",
    "logger.info(f\"Total samples (eval): {len(eval_dataset)}\")\n",
    "logger.info(f\"Batch size: {batch_size}\")\n",
    "logger.info(f\"Epochs: {num_epochs}\")\n",
    "logger.info(f\"Total training steps: {total_train_steps}\")\n",
    "logger.info(f\"Logging steps: {logging_steps}\")\n",
    "logger.info(f\"Save steps: {save_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520,
     "referenced_widgets": [
      "c5babfdb6c4c49b08306b07a8b1cb2e8",
      "2ca6a530dee5433d87a94202507f006e",
      "3b9b0ab5dad04943a9dcbc00b27fe926",
      "0223ac511cb74618b436626cce1e3e4a",
      "1ddaf87ddd5345df87c6c3ffe4eec850",
      "d8dd758c9fc745829252f825c6b47571",
      "e85a87b3bbc141ee8e3bd27cdd52d43a",
      "6c94c0e1ec0b47ed9ea508ab6692cffa",
      "1addbcd6b35b4a6ab0806b3f4758c4d5",
      "b5be49ad85d046ed816296c373f4fd82",
      "a5013117612c4327a5e971b5c79e43c3",
      "568820998ffa4b708718847f9bd8aea2",
      "22213398a3bc4ab493a35fdb38d204f7",
      "125a10c01b81440b9f7f46fd5603c34c",
      "2001a1efdad44c34b2f8301f35adc02a",
      "48cb0b9b3d1b4d20bcefd1da8549f461",
      "9ec1fdb20f594c3d88ccb783decba49b",
      "9557e159383c40618051b9e533cc1e0a",
      "f433c31a3102466bbf12d80e380133f5",
      "146d0de60eed402d94a6a2247787afde",
      "cb5d5a0ef6004ee0854badc266dffaf4",
      "2663f9d29f28471a8c3798b1c6de8eba"
     ]
    },
    "id": "tYCMV9RWUDMo",
    "outputId": "39756527-766e-49a7-cf0a-83876588bca5"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    fp16=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=logging_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=save_steps,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=logging_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=save_total_limit,\n",
    "    report_to=\"none\",\n",
    "    logging_dir=logging_dir\n",
    ")\n",
    "\n",
    "# Trainer 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "trainer.model.save_pretrained(sft_dir)\n",
    "tokenizer.save_pretrained(sft_dir)\n",
    "shutil.make_archive(\"best_sft\", 'zip', sft_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTkuPVYcNHnn",
    "outputId": "00b7c268-c286-458a-b711-392426e34986"
   },
   "outputs": [],
   "source": [
    "total_size = sum(os.path.getsize(os.path.join(root, f))\n",
    "                 for root, _, files in os.walk(sft_dir)\n",
    "                 for f in files)\n",
    "\n",
    "logger.info(f\"Total size of best_sft: {total_size / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4uiZxF0JfAE",
    "outputId": "3bc9488e-84b8-4aec-f30d-39be8a597027"
   },
   "outputs": [],
   "source": [
    "necessary_word = \"[After Train]\"\n",
    "\n",
    "after_response = []\n",
    "for prompt in test_prompts:\n",
    "    after_response.append(test(prompt, model, tokenizer, necessary_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPRtc9roJkkL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
