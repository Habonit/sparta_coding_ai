{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNoVn7GU645YoUQmVu08pxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d492538deeb54d1e876cb92f2e3b6155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_8ed8d92fced64180b29c63d9b959a67b"
          }
        },
        "2d1ffc7fe76244249712e53acd42bf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52284e5945a4da1aefa2df789299aff",
            "placeholder": "​",
            "style": "IPY_MODEL_8246377d54eb4a728ea78caeb6b5c60c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "55b126524e584c8db807891354f6688f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5ca4c2b2e2094bc9bb8b7878db8d380f",
            "placeholder": "​",
            "style": "IPY_MODEL_2875d1d1082342e983fe3e7dfa5a9b67",
            "value": ""
          }
        },
        "db2c8d76e9284f02bbd666bbe847fe6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f7bd83d4573a4859a348fc1798ca29df",
            "style": "IPY_MODEL_7bdf0a6e3ab9476fb61e998df3ac95df",
            "value": true
          }
        },
        "9702f31a6e24406498dcdf767f0fa273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ae5c5381450b4730aee16982ad5645e8",
            "style": "IPY_MODEL_4e87e2a30e0b4fe19f9364f7640b1067",
            "tooltip": ""
          }
        },
        "66ef77e874c74bfdbb0eb92a5bbc29d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5aa3026eab47fc9b4d3132d970c28d",
            "placeholder": "​",
            "style": "IPY_MODEL_669d703d7a4a4099ade8256415221a49",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "8ed8d92fced64180b29c63d9b959a67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "f52284e5945a4da1aefa2df789299aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8246377d54eb4a728ea78caeb6b5c60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ca4c2b2e2094bc9bb8b7878db8d380f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2875d1d1082342e983fe3e7dfa5a9b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7bd83d4573a4859a348fc1798ca29df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bdf0a6e3ab9476fb61e998df3ac95df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5c5381450b4730aee16982ad5645e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e87e2a30e0b4fe19f9364f7640b1067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0b5aa3026eab47fc9b4d3132d970c28d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "669d703d7a4a4099ade8256415221a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "067fc98dcf8d4a3cbb53a3615d2675ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db47f596c2441b096604c78d7550dc6",
            "placeholder": "​",
            "style": "IPY_MODEL_e831a2afa2df403c9d356a7d8775ca82",
            "value": "Connecting..."
          }
        },
        "3db47f596c2441b096604c78d7550dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e831a2afa2df403c9d356a7d8775ca82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61c0f0f5d1de4ee5bef79204a18c3121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a638235c89a43f2996e08e0bd9fdf88",
              "IPY_MODEL_d6a290cf6c434317997bcde0477e1c60",
              "IPY_MODEL_543c855972a34f4fa85bcb1e1d8fada0"
            ],
            "layout": "IPY_MODEL_ae340d938bdc4d559eb9204d6f548210"
          }
        },
        "9a638235c89a43f2996e08e0bd9fdf88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d27d2251dac7455bb18dc9ff4ddaad2d",
            "placeholder": "​",
            "style": "IPY_MODEL_bf959680b0b642d48265ee9b77998c21",
            "value": "Map: 100%"
          }
        },
        "d6a290cf6c434317997bcde0477e1c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27357f9e9fd49c394752f52c7e1a89a",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5eaa73159df4453bab2d351c2c21a810",
            "value": 10
          }
        },
        "543c855972a34f4fa85bcb1e1d8fada0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546c2957d8d9440a9c1dc811bf1c6e1a",
            "placeholder": "​",
            "style": "IPY_MODEL_72e06cba908b4d87bfac5a140b534e58",
            "value": " 10/10 [00:00&lt;00:00, 403.42 examples/s]"
          }
        },
        "ae340d938bdc4d559eb9204d6f548210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d27d2251dac7455bb18dc9ff4ddaad2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf959680b0b642d48265ee9b77998c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c27357f9e9fd49c394752f52c7e1a89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eaa73159df4453bab2d351c2c21a810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "546c2957d8d9440a9c1dc811bf1c6e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e06cba908b4d87bfac5a140b534e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habonit/sparta_coding_ai/blob/main/week7_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week7 Advanced\n",
        "\n",
        "- 1) 과제: SFT trainer를 통해 100개 샘플 훈련\n",
        "\n",
        "- 2) 이번에 논문 요약 서비스를 구현하고 있는데 해당 서비스에 sft로 훈련한 모델을 적용하여 api와의 성능을 비교해볼 것입니다. 이것은 다음주까지 진행할 예정입니다."
      ],
      "metadata": {
        "id": "g7bBNy_R4z0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets transformers trl evaluate rouge_score"
      ],
      "metadata": {
        "id": "CwkaFqkHkSqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "d492538deeb54d1e876cb92f2e3b6155",
            "2d1ffc7fe76244249712e53acd42bf76",
            "55b126524e584c8db807891354f6688f",
            "db2c8d76e9284f02bbd666bbe847fe6b",
            "9702f31a6e24406498dcdf767f0fa273",
            "66ef77e874c74bfdbb0eb92a5bbc29d4",
            "8ed8d92fced64180b29c63d9b959a67b",
            "f52284e5945a4da1aefa2df789299aff",
            "8246377d54eb4a728ea78caeb6b5c60c",
            "5ca4c2b2e2094bc9bb8b7878db8d380f",
            "2875d1d1082342e983fe3e7dfa5a9b67",
            "f7bd83d4573a4859a348fc1798ca29df",
            "7bdf0a6e3ab9476fb61e998df3ac95df",
            "ae5c5381450b4730aee16982ad5645e8",
            "4e87e2a30e0b4fe19f9364f7640b1067",
            "0b5aa3026eab47fc9b4d3132d970c28d",
            "669d703d7a4a4099ade8256415221a49",
            "067fc98dcf8d4a3cbb53a3615d2675ad",
            "3db47f596c2441b096604c78d7550dc6",
            "e831a2afa2df403c9d356a7d8775ca82"
          ]
        },
        "id": "Ng_aqffZmZAc",
        "outputId": "f94955f6-7b9b-4b9a-eb6a-71b4122c5f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d492538deeb54d1e876cb92f2e3b6155"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JSIy9fQm65N",
        "outputId": "0f5d4272-aec4-479a-c148-809603991b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkhk172216\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "\n",
        "-1) 데이터셋을 불러옵니다.\n",
        "\n",
        "-2) train: val: test = 70개 : 20개 : 10개"
      ],
      "metadata": {
        "id": "oN2oo-hz5Yf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"corpus.json\")[\"train\"]\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset = dataset.select(range(train_size))\n",
        "val_dataset = dataset.select(range(train_size, train_size + val_size))\n",
        "test_dataset = dataset.select(range(train_size + val_size, len(dataset)))"
      ],
      "metadata": {
        "id": "1j1UIaDzkRjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_tXoAJAwD31",
        "outputId": "f1bd5634-8038-487a-bc68-430b1917f930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output'],\n",
              "    num_rows: 70\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci75UwR8wE6V",
        "outputId": "90ecccc5-c87c-48c1-adbd-87b70c0312d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output'],\n",
              "    num_rows: 20\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_OjtZxdwF2F",
        "outputId": "7ce4ea1a-6a66-4f92-bcb7-e31eb95afc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset['instruction']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0iUH8VN3uCZ",
        "outputId": "e723d70e-1bd1-4884-d6ed-1cd3db6d34f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['클라우드 AI (Cloud AI)이 무엇인지 설명해줘',\n",
              " 'API 기반 AI 서비스 (AI-as-a-Service)이 무엇인지 설명해줘',\n",
              " '데이터 레이블링 (Data Labeling)이 무엇인지 설명해줘',\n",
              " 'MLOps (Machine Learning Operations)이 무엇인지 설명해줘',\n",
              " 'Explainable AI (XAI, 설명 가능한 AI)이 무엇인지 설명해줘',\n",
              " '시계열 분석 (Time Series Analysis)이 무엇인지 설명해줘',\n",
              " '오픈소스 프레임워크 (TensorFlow, PyTorch)이 무엇인지 설명해줘',\n",
              " 'ONNX (Open Neural Network Exchange)이 무엇인지 설명해줘',\n",
              " 'AutoML (자동화 머신러닝)이 무엇인지 설명해줘',\n",
              " 'AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset['output']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmamdLeF3y2H",
        "outputId": "1a8c354a-6872-4214-c884-8c0053241cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['클라우드 AI는 클라우드 컴퓨팅 환경에서 제공되는 인공지능 기술과 서비스를 의미합니다. 이를 통해 사용자는 대규모 데이터 처리, 기계 학습, 자연어 처리 등의 AI 기능을 쉽게 활용할 수 있습니다. 클라우드 AI는 일반적으로 높은 처리 능력과 저장 용량을 제공하여 기업과 개인이 복잡한 AI 모델을 학습시키고 운영할 수 있도록 돕습니다. 또한, 사용자는 필요에 따라 리소스를 확장하거나 축소할 수 있어 유연한 비용 관리를 할 수 있습니다. 대표적인 클라우드 AI 서비스에는 구글 클라우드 AI, 아마존 웹 서비스(AWS), 마이크로소프트 애저 등이 있습니다.',\n",
              " 'API 기반 AI 서비스(AI-as-a-Service)는 클라우드 기반 플랫폼에서 AI 기능을 제공하는 서비스입니다. 사용자는 복잡한 AI 모델을 구축하지 않고도 API를 통해 기계 학습, 자연어 처리, 이미지 분석 등의 기능을 쉽게 활용할 수 있습니다. 이러한 서비스는 개발자들이 빠르게 AI 기술을 통합하여 애플리케이션을 개발할 수 있도록 지원합니다. 또한, 비용 효율성 및 확장성을 제공하여 필요에 따라 서비스를 이용할 수 있는 장점이 있습니다. 대표적인 예로는 구글의 AI 플랫폼, 아마존의 SageMaker 등이 있습니다.',\n",
              " \"데이터 레이블링(Data Labeling)은 기계 학습과 인공지능 모델을 학습시키기 위해 데이터를 식별하고 주석을 달아주는 과정입니다. 이 과정에서는 이미지, 텍스트, 오디오 등의 데이터에 특정 태그나 클래스를 부여하여 모델이 데이터를 이해할 수 있게 만듭니다. 예를 들어, 이미지 인식 모델을 위해 고양이와 개의 이미지를 각각 '고양이', '개'로 레이블링할 수 있습니다. 데이터 레이블링은 일반적으로 수작업으로 이루어지며, 정확한 레이블링이 모델의 성능에 큰 영향을 미칩니다. 최근에는 자동화된 레이블링 도구나 반자동화 기법도 개발되고 있습니다.\",\n",
              " 'MLOps는 머신러닝 모델의 개발, 배포, 운영 및 유지 관리를 위한 실용적인 방법론입니다. 이는 IT 운영과 데이터 과학 팀 간의 협업을 촉진하여 머신러닝 프로젝트의 생애 주기를 관리합니다. MLOps는 자동화, 버전 관리, 테스트 및 모니터링을 포함하여 모델의 품질과 신뢰성을 높이는 데 기여합니다. 이를 통해 기업은 더 빠르고 효율적으로 머신러닝 모델을 배포하고 성능을 유지할 수 있습니다. 궁극적으로 MLOps는 비즈니스 가치 창출을 위한 머신러닝 솔루션의 효과적인 운영을 지향합니다.',\n",
              " '설명 가능한 AI(Explainable AI, XAI)는 인공지능의 결정 과정과 결과를 이해할 수 있도록 도와주는 기술입니다. 이는 사용자들이 AI의 결정이 어떻게 이루어졌는지, 어떤 요소가 영향을 미쳤는지를 알 수 있게 해줍니다. XAI의 목적은 AI 모델의 투명성을 높이고, 신뢰성을 강화하여 사용자가 쉽게 수용할 수 있도록 하는 것입니다. 특히 의료, 금융, 자율주행 차량 등 신뢰성이 중요한 분야에서 XAI의 필요성이 더욱 두드러집니다. 따라서 설명 가능한 AI는 인간과 AI 간의 협력 관계를 더욱 원활하게 만드는 데 중요한 역할을 합니다.',\n",
              " '시계열 분석은 시간에 따라 변화하는 데이터를 분석하는 방법입니다. 이 분석은 과거 데이터를 기반으로 미래의 값을 예측하는 데 주로 사용됩니다. 보통 주식 가격, 기온 변화, 판매량 등과 같은 데이터에 적용됩니다. 시계열 데이터는 시간 순서가 중요하므로, 시계열 모델링에서는 자기상관, 계절성, 추세와 같은 요소를 고려합니다. 이를 통해 데이터의 패턴을 파악하고, 효율적인 의사결정을 지원할 수 있습니다.',\n",
              " '오픈소스 프레임워크는 개발자들이 소스 코드를 자유롭게 사용, 변경 및 배포할 수 있도록 허용하는 소프트웨어입니다. TensorFlow와 PyTorch는 특히 머신러닝과 딥러닝 분야에서 널리 사용되는 오픈소스 프레임워크입니다. TensorFlow는 구글에 의해 개발되었으며, 대규모 모델을 훈련하는 데 강점을 가지고 있습니다. 반면, PyTorch는 페이스북에서 개발되어 직관적인 코드 작성과 빠른 프로토타이핑에 적합합니다. 두 프레임워크 모두 커뮤니티의 활발한 지원을 받아 많은 라이브러리와 도구들이 개발되고 있습니다.',\n",
              " 'ONNX(Open Neural Network Exchange)는 다양한 딥러닝 프레임워크 간의 상호 운용성을 촉진하기 위한 오픈 소스 형식입니다. 이 포맷을 사용하면, 한 프레임워크에서 학습된 모델을 다른 프레임워크로 쉽게 변환하고 사용할 수 있습니다. ONNX는 주로 PyTorch, TensorFlow, Caffe2와 같은 인기 있는 딥러닝 라이브러리와 호환됩니다. 모델의 표준화된 표현 덕분에 개발자들은 다양한 플랫폼과 툴에서 동일한 모델을 활용할 수 있습니다. 이를 통해 연구자와 엔지니어는 더 효율적으로 작업할 수 있으며, 딥러닝 모델의 배포와 운영이 한층 수월해집니다.',\n",
              " 'AutoML(자동화 머신러닝)은 머신러닝 모델을 자동으로 생성하고 최적화하는 프로세스를 의미합니다. 이를 통해 비전문가도 데이터 분석과 머신러닝의 복잡한 과정을 쉽게 수행할 수 있습니다. AutoML은 데이터 전처리, 모델 선택, 하이퍼파라미터 튜닝 등의 과정을 자동화하여 효율성을 높입니다. 다양한 AutoML 도구와 플랫폼이 존재하며, 사용자는 이를 활용하여 빠르게 모델을 개발하고 배포할 수 있습니다. 궁극적으로 AutoML은 데이터 사이언스의 접근성을 높이고, 더 많은 사람들이 머신러닝 기술을 활용할 수 있도록 돕는 역할을 합니다.',\n",
              " 'AI 모델 배포는 개발된 인공지능 모델을 실제 운영 환경에 적용하여 사용자나 다른 시스템이 활용할 수 있도록 하는 과정입니다. 이 과정에는 모델을 서버에 설치하고, API를 통해 접근할 수 있도록 설정하는 작업이 포함됩니다. 또한, 성능 모니터링과 유지보수를 통해 모델의 효율성을 지속적으로 관리하는 것이 중요합니다. 배포된 모델은 데이터를 실시간으로 처리하고, 예측 결과를 제공하여 다양한 비즈니스 문제를 해결하는 데 기여합니다. 마지막으로, 배포 후에는 사용자 피드백을 받아 모델을 개선하는 과정도 필요합니다.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "- 1) 대표적인 모델인 LLAMA 3.2 1b 모델을 사용합니다.\n",
        "\n",
        "- 2) LLAMA는 SFT를 진행하기 위해선 {\"text\": prompt} 데이터를 만들면 됩니다."
      ],
      "metadata": {
        "id": "-zu3GDpG5rUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\").to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # LLaMA는 기본적으로 pad_token이 없으므로 eos_token 사용\n",
        "\n",
        "def format_llama_prompt(example):\n",
        "    prompt = f\"### 질문: {example['instruction']}\\n### 답변: {example['output']}\"\n",
        "    return {\"text\": prompt}\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(format_llama_prompt).map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(format_llama_prompt).map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(format_llama_prompt).map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "61c0f0f5d1de4ee5bef79204a18c3121",
            "9a638235c89a43f2996e08e0bd9fdf88",
            "d6a290cf6c434317997bcde0477e1c60",
            "543c855972a34f4fa85bcb1e1d8fada0",
            "ae340d938bdc4d559eb9204d6f548210",
            "d27d2251dac7455bb18dc9ff4ddaad2d",
            "bf959680b0b642d48265ee9b77998c21",
            "c27357f9e9fd49c394752f52c7e1a89a",
            "5eaa73159df4453bab2d351c2c21a810",
            "546c2957d8d9440a9c1dc811bf1c6e1a",
            "72e06cba908b4d87bfac5a140b534e58"
          ]
        },
        "id": "Te0B0wGYkxt_",
        "outputId": "d48dc4bf-f985-49a1-c0c8-48ff3c67cef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61c0f0f5d1de4ee5bef79204a18c3121"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Args Setting"
      ],
      "metadata": {
        "id": "xYLad4AG6Ds8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./llama-3.2-1B-sft\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "    fp16=True,\n",
        "    save_total_limit=2,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"wandb\",\n",
        "    run_name=\"week7_advanced_llama_finetuning\",\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOW17pvs1A7r",
        "outputId": "f57114c1-9eca-4902-8156-e428613c740e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-13-3b5126fad110>:27: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SFTTrainer(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric Comparision\n",
        "\n",
        "- 1) Bleu와 Rouge Score를 사용하여 훈련 전후의 매트릭을 비교해 훈련의 효과를 검증해볼 예정입니다.\n",
        "\n",
        "- 2) 나아가 훈련한 모델이 generate한 output과 openai api로 제작한 데이터와의 차이를 육안으로 확인해볼 예정입니다."
      ],
      "metadata": {
        "id": "hFjYvbO0668q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def generate_responses(prompts, max_length=256):\n",
        "    inputs = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")  # 배치 처리\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(**inputs, max_new_tokens=max_length, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    responses = tokenizer.batch_decode(output_ids, skip_special_tokens=True)  # 배치 디코딩\n",
        "    return responses\n",
        "\n",
        "prompts = test_dataset[\"instruction\"]\n",
        "outputs = test_dataset[\"output\"]\n",
        "generated_responses = generate_responses(prompts)\n",
        "\n",
        "for prompt, output, response in zip(prompts, outputs, generated_responses):\n",
        "    print(f\"\\n🔹 질문: {prompt}\")\n",
        "    print(f\"\\n🔹 응답: {output}\")\n",
        "    print(f\"🔹 모델 응답: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPQUED271Ikx",
        "outputId": "146fb878-1c71-4ea7-e9f0-fed490da970d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 질문: 클라우드 AI (Cloud AI)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 클라우드 AI는 클라우드 컴퓨팅 환경에서 제공되는 인공지능 기술과 서비스를 의미합니다. 이를 통해 사용자는 대규모 데이터 처리, 기계 학습, 자연어 처리 등의 AI 기능을 쉽게 활용할 수 있습니다. 클라우드 AI는 일반적으로 높은 처리 능력과 저장 용량을 제공하여 기업과 개인이 복잡한 AI 모델을 학습시키고 운영할 수 있도록 돕습니다. 또한, 사용자는 필요에 따라 리소스를 확장하거나 축소할 수 있어 유연한 비용 관리를 할 수 있습니다. 대표적인 클라우드 AI 서비스에는 구글 클라우드 AI, 아마존 웹 서비스(AWS), 마이크로소프트 애저 등이 있습니다.\n",
            "🔹 모델 응답: 클라우드 AI (Cloud AI)이 무엇인지 설명해줘#1\n",
            "Cloud AI는 클라우드 컴퓨팅 환경에서 컴퓨팅 리소스를 사용하는 것에 대한 의미이다. 클라우드 컴퓨팅의 특징을 살펴보면 다음과 같은 점을 알아보자.\n",
            "- 클라우드 컴퓨팅은 컴퓨팅 리소스를 사용하는 방법을 모니터링 및 관리하는 것에 집중한다.\n",
            "- 클라우드 컴퓨팅은 컴퓨팅 리소스를 사용하는 방법을 모니터링 및 관리하는 것이 아니라 컴퓨팅 리소스에 대한 리소스 관리를 하는 것에 집중한다.\n",
            "- 클라우드 컴퓨팅은 컴퓨팅 리소스에 대한 리소스 관리를 하는 것에 집중한다.\n",
            "- 클라우드 컴퓨팅은 컴퓨팅 리소스를 사용하는 방법을 모니터링 및 관리하는 것이 아니라 컴퓨팅 리소스에 대한 리소스 관리를 하는 것에 집중한다.\n",
            "- 클라우드 컴퓨팅은 컴퓨팅 리소스를 사용하는 방법을 모니터링 및 관리하는 것이 아니라 컴퓨팅 리소스에 대한 리소스 관리를 하는 것에 집\n",
            "\n",
            "🔹 질문: API 기반 AI 서비스 (AI-as-a-Service)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: API 기반 AI 서비스(AI-as-a-Service)는 클라우드 기반 플랫폼에서 AI 기능을 제공하는 서비스입니다. 사용자는 복잡한 AI 모델을 구축하지 않고도 API를 통해 기계 학습, 자연어 처리, 이미지 분석 등의 기능을 쉽게 활용할 수 있습니다. 이러한 서비스는 개발자들이 빠르게 AI 기술을 통합하여 애플리케이션을 개발할 수 있도록 지원합니다. 또한, 비용 효율성 및 확장성을 제공하여 필요에 따라 서비스를 이용할 수 있는 장점이 있습니다. 대표적인 예로는 구글의 AI 플랫폼, 아마존의 SageMaker 등이 있습니다.\n",
            "🔹 모델 응답: API 기반 AI 서비스 (AI-as-a-Service)이 무엇인지 설명해줘This article describes the definition of API-based AI service (AI as a Service).\n",
            "API 기반 AI 서비스 (AI as a Service)란 무엇인가?\n",
            "API 기반 AI 서비스는 AI 기술을 사용하여 애플리케이션과 데이터를 연결하는 것에 집중하고, 데이터를 조합하고, 모형화하고, 학습하고, 모델을 생성하고, 학습에 대한 결과를 제공하는 서비스이다. AI 기술을 사용하여 애플리케이션과 데이터를 연결하는 것에 집중하고, 데이터를 조합하고, 모형화하고, 학습하고, 모델을 생성하고, 학습에 대한 결과를 제공하는 서비스이다.\n",
            "\n",
            "🔹 질문: 데이터 레이블링 (Data Labeling)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 데이터 레이블링(Data Labeling)은 기계 학습과 인공지능 모델을 학습시키기 위해 데이터를 식별하고 주석을 달아주는 과정입니다. 이 과정에서는 이미지, 텍스트, 오디오 등의 데이터에 특정 태그나 클래스를 부여하여 모델이 데이터를 이해할 수 있게 만듭니다. 예를 들어, 이미지 인식 모델을 위해 고양이와 개의 이미지를 각각 '고양이', '개'로 레이블링할 수 있습니다. 데이터 레이블링은 일반적으로 수작업으로 이루어지며, 정확한 레이블링이 모델의 성능에 큰 영향을 미칩니다. 최근에는 자동화된 레이블링 도구나 반자동화 기법도 개발되고 있습니다.\n",
            "🔹 모델 응답: 데이터 레이블링 (Data Labeling)이 무엇인지 설명해줘\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 레이블링하는 방법을 말한다.\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용하는 방법\n",
            "- 데이터 레이블링은 데이터를 분류할 목적으로 사용\n",
            "\n",
            "🔹 질문: MLOps (Machine Learning Operations)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: MLOps는 머신러닝 모델의 개발, 배포, 운영 및 유지 관리를 위한 실용적인 방법론입니다. 이는 IT 운영과 데이터 과학 팀 간의 협업을 촉진하여 머신러닝 프로젝트의 생애 주기를 관리합니다. MLOps는 자동화, 버전 관리, 테스트 및 모니터링을 포함하여 모델의 품질과 신뢰성을 높이는 데 기여합니다. 이를 통해 기업은 더 빠르고 효율적으로 머신러닝 모델을 배포하고 성능을 유지할 수 있습니다. 궁극적으로 MLOps는 비즈니스 가치 창출을 위한 머신러닝 솔루션의 효과적인 운영을 지향합니다.\n",
            "🔹 모델 응답: MLOps (Machine Learning Operations)이 무엇인지 설명해줘The purpose of this course is to introduce you to the Machine Learning Operations (MLOps) movement. We will cover the basics of MLOps, how it differs from the traditional machine learning lifecycle, and how it is evolving to become a core discipline of machine learning.\n",
            "The MLOps movement is still in its infancy. It has not yet achieved a consensus on the best practices for MLOps. But it is gaining momentum, and we expect it to become a core discipline of machine learning. The course will cover the basics of MLOps, how it differs from the traditional machine learning lifecycle, and how it is evolving to become a core discipline of machine learning.\n",
            "What is MLOps?\n",
            "MLOps is a new discipline that emerged from the need to scale and automate machine learning (ML) systems. MLOps is an umbrella term that includes a number of related but distinct practices. These practices are sometimes referred to as the “machine learning lifecycle” or the “machine learning pipeline.”\n",
            "MLOps is an approach to machine learning that focuses on the management of machine learning systems from the initial data collection through the training, deployment, monitoring, and management of machine learning systems. It is not a specific technology, but rather a set of practices and techniques\n",
            "\n",
            "🔹 질문: Explainable AI (XAI, 설명 가능한 AI)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 설명 가능한 AI(Explainable AI, XAI)는 인공지능의 결정 과정과 결과를 이해할 수 있도록 도와주는 기술입니다. 이는 사용자들이 AI의 결정이 어떻게 이루어졌는지, 어떤 요소가 영향을 미쳤는지를 알 수 있게 해줍니다. XAI의 목적은 AI 모델의 투명성을 높이고, 신뢰성을 강화하여 사용자가 쉽게 수용할 수 있도록 하는 것입니다. 특히 의료, 금융, 자율주행 차량 등 신뢰성이 중요한 분야에서 XAI의 필요성이 더욱 두드러집니다. 따라서 설명 가능한 AI는 인간과 AI 간의 협력 관계를 더욱 원활하게 만드는 데 중요한 역할을 합니다.\n",
            "🔹 모델 응답: Explainable AI (XAI, 설명 가능한 AI)이 무엇인지 설명해줘#explainableai #machinelearning #ml #deeplearning #python #datascience #ml #mlmodel #mltraining #mlmodel #machinelearning #machinelearning #datascience #dataanalysis #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst #dataanalyst\n",
            "\n",
            "🔹 질문: 시계열 분석 (Time Series Analysis)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 시계열 분석은 시간에 따라 변화하는 데이터를 분석하는 방법입니다. 이 분석은 과거 데이터를 기반으로 미래의 값을 예측하는 데 주로 사용됩니다. 보통 주식 가격, 기온 변화, 판매량 등과 같은 데이터에 적용됩니다. 시계열 데이터는 시간 순서가 중요하므로, 시계열 모델링에서는 자기상관, 계절성, 추세와 같은 요소를 고려합니다. 이를 통해 데이터의 패턴을 파악하고, 효율적인 의사결정을 지원할 수 있습니다.\n",
            "🔹 모델 응답: 시계열 분석 (Time Series Analysis)이 무엇인지 설명해줘We consider the problem of determining the number of states from a sequence of measurements. The problem is formulated as a Markov decision process (MDP). We present a simple and efficient algorithm for solving this problem. The algorithm is based on a novel approach to MDPs. We develop a new class of MDPs that are defined by a set of parameters and a set of constraints. The parameters are the number of states and the transition probabilities of the MDP. The constraints are the transition probabilities and the costs of the states. We show that the number of states is the minimum number of states that satisfy the constraints and the transition probabilities. We also show that the number of states is a lower bound on the number of states that satisfy the constraints and the transition probabilities. We develop an algorithm to find the number of states from a sequence of measurements. The algorithm is based on a novel approach to MDPs. We develop a new class of MDPs that are defined by a set of parameters and a set of constraints. The parameters are the number of states and the transition probabilities of the MDP. The constraints are the transition probabilities and the costs of the states. We show that the number of states is the minimum number of states that satisfy the constraints and the\n",
            "\n",
            "🔹 질문: 오픈소스 프레임워크 (TensorFlow, PyTorch)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 오픈소스 프레임워크는 개발자들이 소스 코드를 자유롭게 사용, 변경 및 배포할 수 있도록 허용하는 소프트웨어입니다. TensorFlow와 PyTorch는 특히 머신러닝과 딥러닝 분야에서 널리 사용되는 오픈소스 프레임워크입니다. TensorFlow는 구글에 의해 개발되었으며, 대규모 모델을 훈련하는 데 강점을 가지고 있습니다. 반면, PyTorch는 페이스북에서 개발되어 직관적인 코드 작성과 빠른 프로토타이핑에 적합합니다. 두 프레임워크 모두 커뮤니티의 활발한 지원을 받아 많은 라이브러리와 도구들이 개발되고 있습니다.\n",
            "🔹 모델 응답: 오픈소스 프레임워크 (TensorFlow, PyTorch)이 무엇인지 설명해줘요.\n",
            "TensorFlow는 계산기능을 제공하는 프레임워크로, PyTorch는 프레임워크를 구현한 것인데, 둘 다 오픈소스이다.\n",
            "이 글에서는 TensorFlow를 사용하여 머신러닝을 수행하는 방법을 설명하려고 합니다.\n",
            "머신러닝을 수행하는 이유\n",
            "머신러닝을 수행하는 이유는 데이터가 많고, 데이터가 많아질수록 더 많은 데이터를 사용하여 더 좋은 결과를 얻을 수 있다. 하지만, 데이터가 많아질수록 더 많은 컴퓨터가 필요하기 때문에, 더 많은 컴퓨터를 사용하여 더 많은 데이터를 처리할 수 있도록 도와주는 것이 머신러닝의 목적이다.\n",
            "이러한 문제를 해결하기 위해 머신러닝을 수행하는 방법이 있다.\n",
            "이러한 방법을 사용하면, 머신러닝을 수행할 때, 데이터를 처리하는 데 필요한 많은 컴퓨터의 시간과 자원을 절약할 수 있다.\n",
            "머신러닝을 수행하는 방법\n",
            "머신러닝을 수행할 때, 데이터를 처리하는 데 필요한 많은 컴퓨터의 시간과 자원을 절약하기 위해, 머신러닝을 수행하는 방법\n",
            "\n",
            "🔹 질문: ONNX (Open Neural Network Exchange)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: ONNX(Open Neural Network Exchange)는 다양한 딥러닝 프레임워크 간의 상호 운용성을 촉진하기 위한 오픈 소스 형식입니다. 이 포맷을 사용하면, 한 프레임워크에서 학습된 모델을 다른 프레임워크로 쉽게 변환하고 사용할 수 있습니다. ONNX는 주로 PyTorch, TensorFlow, Caffe2와 같은 인기 있는 딥러닝 라이브러리와 호환됩니다. 모델의 표준화된 표현 덕분에 개발자들은 다양한 플랫폼과 툴에서 동일한 모델을 활용할 수 있습니다. 이를 통해 연구자와 엔지니어는 더 효율적으로 작업할 수 있으며, 딥러닝 모델의 배포와 운영이 한층 수월해집니다.\n",
            "🔹 모델 응답: ONNX (Open Neural Network Exchange)이 무엇인지 설명해줘#1\n",
            "\n",
            "\n",
            "🔹 질문: AutoML (자동화 머신러닝)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: AutoML(자동화 머신러닝)은 머신러닝 모델을 자동으로 생성하고 최적화하는 프로세스를 의미합니다. 이를 통해 비전문가도 데이터 분석과 머신러닝의 복잡한 과정을 쉽게 수행할 수 있습니다. AutoML은 데이터 전처리, 모델 선택, 하이퍼파라미터 튜닝 등의 과정을 자동화하여 효율성을 높입니다. 다양한 AutoML 도구와 플랫폼이 존재하며, 사용자는 이를 활용하여 빠르게 모델을 개발하고 배포할 수 있습니다. 궁극적으로 AutoML은 데이터 사이언스의 접근성을 높이고, 더 많은 사람들이 머신러닝 기술을 활용할 수 있도록 돕는 역할을 합니다.\n",
            "🔹 모델 응답: AutoML (자동화 머신러닝)이 무엇인지 설명해줘#8\n",
            "#3차 산업혁명, AI, ML, 빅데이터, Machine Learning, 머신러닝, 인공지능, 자동화 머신러닝, 머신러닝, 머신러닝을 활용한 AI, ML, 빅데이터, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI, ML, 빅데이터를 활용한 AI,\n",
            "\n",
            "🔹 질문: AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: AI 모델 배포는 개발된 인공지능 모델을 실제 운영 환경에 적용하여 사용자나 다른 시스템이 활용할 수 있도록 하는 과정입니다. 이 과정에는 모델을 서버에 설치하고, API를 통해 접근할 수 있도록 설정하는 작업이 포함됩니다. 또한, 성능 모니터링과 유지보수를 통해 모델의 효율성을 지속적으로 관리하는 것이 중요합니다. 배포된 모델은 데이터를 실시간으로 처리하고, 예측 결과를 제공하여 다양한 비즈니스 문제를 해결하는 데 기여합니다. 마지막으로, 배포 후에는 사용자 피드백을 받아 모델을 개선하는 과정도 필요합니다.\n",
            "🔹 모델 응답: AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘 2분 25초만에\n",
            "==========================\n",
            "<br>\n",
            "1. [AWS CloudWatch 로그를 사용하여 데이터 수집](./data-collection.md)  \n",
            "2. [AWS CloudWatch Logs을 사용하여 로그를 수집](./logs-collecting.md)  \n",
            "3. [AWS CodeBuild를 사용하여 배포](./codebuild.md)  \n",
            "4. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "5. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "6. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "7. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "8. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "9. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "10. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "11. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "12. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)  \n",
            "13. [AWS CodePipeline를 사용하여 배포](./codepipeline.md)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(predictions, references):\n",
        "    bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
        "    rouge_score = rouge.compute(predictions=predictions, references=references)\n",
        "\n",
        "    return {\n",
        "        \"bleu\": bleu_score[\"bleu\"],\n",
        "        \"rouge1\": rouge_score[\"rouge1\"],\n",
        "        \"rouge2\": rouge_score[\"rouge2\"],\n",
        "        \"rougeL\": rouge_score[\"rougeL\"],\n",
        "    }\n",
        "\n",
        "metrics = compute_metrics(generated_responses, outputs)\n",
        "\n",
        "print(\"\\n📊 Evaluation Metrics:\")\n",
        "print(f\"🔹 BLEU Score: {metrics['bleu']:.4f}\")\n",
        "print(f\"🔹 ROUGE-1: {metrics['rouge1']:.4f}\")\n",
        "print(f\"🔹 ROUGE-2: {metrics['rouge2']:.4f}\")\n",
        "print(f\"🔹 ROUGE-L: {metrics['rougeL']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2tBxzZ403aS",
        "outputId": "47cc20eb-2337-43ed-a4ab-69a8e906b018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Evaluation Metrics:\n",
            "🔹 BLEU Score: 0.0222\n",
            "🔹 ROUGE-1: 0.3702\n",
            "🔹 ROUGE-2: 0.2968\n",
            "🔹 ROUGE-L: 0.3702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "GR_de2mors6Q",
        "outputId": "b206ff46-a5e3-446b-ab4b-d79aaeb7c177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250206_151604-rb991mo1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/khk172216/huggingface/runs/rb991mo1' target=\"_blank\">week7_advanced_llama_finetuning</a></strong> to <a href='https://wandb.ai/khk172216/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/khk172216/huggingface' target=\"_blank\">https://wandb.ai/khk172216/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/khk172216/huggingface/runs/rb991mo1' target=\"_blank\">https://wandb.ai/khk172216/huggingface/runs/rb991mo1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 07:37, Epoch 6/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.761000</td>\n",
              "      <td>1.603453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.151800</td>\n",
              "      <td>1.534319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.783300</td>\n",
              "      <td>1.630451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.493400</td>\n",
              "      <td>1.656896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>1.727832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.187400</td>\n",
              "      <td>1.772976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=20, training_loss=0.7345024943351746, metrics={'train_runtime': 461.1183, 'train_samples_per_second': 1.518, 'train_steps_per_second': 0.043, 'total_flos': 1446920350334976.0, 'train_loss': 0.7345024943351746, 'epoch': 6.888888888888889})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_results = trainer.evaluate(test_dataset)\n",
        "trained_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "2cRqtGV6nX8Z",
        "outputId": "bed7e37a-5292-4424-8951-fa7e9fbdac86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.4758316278457642,\n",
              " 'eval_runtime': 0.1739,\n",
              " 'eval_samples_per_second': 57.488,\n",
              " 'eval_steps_per_second': 17.246,\n",
              " 'epoch': 6.888888888888889}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompts = test_dataset[\"instruction\"]\n",
        "outputs = test_dataset[\"output\"]\n",
        "generated_responses = generate_responses(prompts)\n",
        "\n",
        "for prompt, output, response in zip(prompts, outputs, generated_responses):\n",
        "    print(f\"\\n🔹 질문: {prompt}\")\n",
        "    print(f\"\\n🔹 응답: {output}\")\n",
        "    print(f\"🔹 모델 응답: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwQTuDqep1vB",
        "outputId": "cb4c22e9-c1a9-4341-e10d-52fc0cd48c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 질문: 클라우드 AI (Cloud AI)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 클라우드 AI는 클라우드 컴퓨팅 환경에서 제공되는 인공지능 기술과 서비스를 의미합니다. 이를 통해 사용자는 대규모 데이터 처리, 기계 학습, 자연어 처리 등의 AI 기능을 쉽게 활용할 수 있습니다. 클라우드 AI는 일반적으로 높은 처리 능력과 저장 용량을 제공하여 기업과 개인이 복잡한 AI 모델을 학습시키고 운영할 수 있도록 돕습니다. 또한, 사용자는 필요에 따라 리소스를 확장하거나 축소할 수 있어 유연한 비용 관리를 할 수 있습니다. 대표적인 클라우드 AI 서비스에는 구글 클라우드 AI, 아마존 웹 서비스(AWS), 마이크로소프트 애저 등이 있습니다.\n",
            "🔹 모델 응답: 클라우드 AI (Cloud AI)이 무엇인지 설명해줘def cloud_ai(cloud_ai):\n",
            "    \"\"\"클라우드 AI는 인공지능 (Artificial Intelligence, AI)이 클라우드 컴퓨팅을 통해 수행되는 인공지능 시스템입니다. 클라우드 AI는 컴퓨터 과학, 인공지능, 머신러닝, 딥러닝 등의 다양한 분야에서 활용됩니다. 클라우드 AI는 데이터 분석, 이미지 처리, 게임 인공지능, 의료 AI 등 다양한 분야에서 활용되고 있습니다. 클라우드 AI는 다양한 컴퓨팅 장치와 데이터베이스를 사용하여 빠르고 효율적으로 처리할 수 있어 더 빠르고 효과적인 인공지능 시스템을 만들 수 있습니다. 클라우드 AI는 데이터 분석, 의료 치료, 게임 디자인 등 다양한 분야에서 활용되고 있습니다. 클라우드 AI는 인공지능 기술을 활용하여 데이터를 분석하고 모델을 학습하여 인공지능 시스템을 만들고, 이를 통해 더 많은 데이터를 사용하여 더 잘 맞춘 모델을 만들 수 있습니다. 클라우드 AI는 인공지능의 발전을 촉진시키고, 더 많은 분야에서 활용될 수 있는 기회를 제공합니다. 클라우드 AI는 인\n",
            "\n",
            "🔹 질문: API 기반 AI 서비스 (AI-as-a-Service)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: API 기반 AI 서비스(AI-as-a-Service)는 클라우드 기반 플랫폼에서 AI 기능을 제공하는 서비스입니다. 사용자는 복잡한 AI 모델을 구축하지 않고도 API를 통해 기계 학습, 자연어 처리, 이미지 분석 등의 기능을 쉽게 활용할 수 있습니다. 이러한 서비스는 개발자들이 빠르게 AI 기술을 통합하여 애플리케이션을 개발할 수 있도록 지원합니다. 또한, 비용 효율성 및 확장성을 제공하여 필요에 따라 서비스를 이용할 수 있는 장점이 있습니다. 대표적인 예로는 구글의 AI 플랫폼, 아마존의 SageMaker 등이 있습니다.\n",
            "🔹 모델 응답: API 기반 AI 서비스 (AI-as-a-Service)이 무엇인지 설명해줘byline: AI-as-a-Service (AIaaS)는 인공지능 (AI) 기술을 사용하여 소프트웨어, 서비스, 또는 데이터를 생성, 처리, 변형, 또는 활용하는 데 필요한 비용을 별도로 내지불과 하지 않고, 사용자에게 필요한 시간에 사용 가능한 가격을 제공하는 기술입니다. 이를 통해 AI 서비스는 비용 효율성이 높은, 효율적인 비용 구조를 갖추게 합니다. AIaaS는 특히 소비자용, 비즈니스용, 교육용, 의료용, 이미지 처리, 딥러닝, 자연어 처리 등 다양한 분야에서 활용되고 있습니다. 이 기술은 인공지능, 머신러닝, 딥러닝, 인공지능 인공지능 (AI)이 무엇인지 설명해줘 byline: 인공지능 (AI)은 컴퓨터 과학의 한 분야로, 컴퓨터 시스템이 인간의 감정, 의견, 행동, 또는 의사결정에 대한 인식, 감정, 또는 행동을 학습하고 학습 데이터를 기반으로 학습 모델을 생성합니다. 이 모델은 데이터를 통해 데이터셋을 학습하고, 이후 다양한 응용 분야에서 사용됩니다. 인공지\n",
            "\n",
            "🔹 질문: 데이터 레이블링 (Data Labeling)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 데이터 레이블링(Data Labeling)은 기계 학습과 인공지능 모델을 학습시키기 위해 데이터를 식별하고 주석을 달아주는 과정입니다. 이 과정에서는 이미지, 텍스트, 오디오 등의 데이터에 특정 태그나 클래스를 부여하여 모델이 데이터를 이해할 수 있게 만듭니다. 예를 들어, 이미지 인식 모델을 위해 고양이와 개의 이미지를 각각 '고양이', '개'로 레이블링할 수 있습니다. 데이터 레이블링은 일반적으로 수작업으로 이루어지며, 정확한 레이블링이 모델의 성능에 큰 영향을 미칩니다. 최근에는 자동화된 레이블링 도구나 반자동화 기법도 개발되고 있습니다.\n",
            "🔹 모델 응답: 데이터 레이블링 (Data Labeling)이 무엇인지 설명해줘-데이터 레이블링 (Data Labeling)은 데이터를 레이블로 인식하고, 이를 기반으로 데이터 분석을 수행하는 과정입니다. 데이터 레이블링은 데이터 분석, 데이터베이스 관리, 머신러닝, 데이터 가중치를 계산하는 데 사용됩니다. 데이터 레이블링은 데이터를 활용하여 데이터의 의미를 설명하고, 데이터의 패턴을 파악하는 데 유용합니다. 데이터 레이블링은 데이터 분석, 머신러닝, 데이터베이스 관리, 그리고 의료 분야에서 널리 사용되고 있습니다. 데이터 레이블링은 데이터의 의미를 이해하고 활용하는 데 중요한 역할을 하며, 데이터를 더 효과적으로 활용할 수 있도록 돕습니다. 데이터 레이블링은 데이터 분석, 데이터베이스 관리, 머신러닝, 데이터 가중치를 계산하는 데 유용합니다. 데이터 레이블링은 데이터의 의미를 설명하고, 데이터의 패턴을 이해하는 데 중요한 역할을 합니다. 데이터 레이블링은 데이터의 의미를 설명하고, 데이터의 패턴을 이해하는 데 중요한 역할을 합니다. 데이터 레이블링은 데이터 분석, 데이터베이스 관리, 머신러닝, 데이터 가\n",
            "\n",
            "🔹 질문: MLOps (Machine Learning Operations)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: MLOps는 머신러닝 모델의 개발, 배포, 운영 및 유지 관리를 위한 실용적인 방법론입니다. 이는 IT 운영과 데이터 과학 팀 간의 협업을 촉진하여 머신러닝 프로젝트의 생애 주기를 관리합니다. MLOps는 자동화, 버전 관리, 테스트 및 모니터링을 포함하여 모델의 품질과 신뢰성을 높이는 데 기여합니다. 이를 통해 기업은 더 빠르고 효율적으로 머신러닝 모델을 배포하고 성능을 유지할 수 있습니다. 궁극적으로 MLOps는 비즈니스 가치 창출을 위한 머신러닝 솔루션의 효과적인 운영을 지향합니다.\n",
            "🔹 모델 응답: MLOps (Machine Learning Operations)이 무엇인지 설명해줘#MLOps (Machine Learning Operations)는 머신러닝 (Machine Learning) 모델을 개발, 학습, 검증, 인식, 운영, 유지보수하는 과정입니다. 이는 데이터를 통해 모델이 무엇인지 설명해줘, 모델 성능을 평가해줘 등의 기능을 제공합니다. 이를 통해 머신러닝 모델의 효율성을 높이고 모델 성능을 향상시키기 위해 MLOps의 중요성을 설명해줘 MLOps는 머신러닝 모델을 관리하는 데 필요한 다양한 기술을 사용하여 모델의 효율성을 높이고 성능을 향상시키는 데 기여합니다. 이를 통해 머신러닝 모델의 활용도가 높은 경향을 가지게 됩니다. MLOps는 데이터 scientists, 데이터 엔지니어, 데이터 분석가, 그리고 머신러닝 전문가들에서 사용됩니다. 이 기술은 머신러닝 모델을 효과적으로 활용하려는 데 중요한 역할을 합니다. 따라서 MLOps는 머신러닝 분야에서 중요한 역할을 합니다. 이를 통해 머신러닝 모델의 성능 향상과 확장성 확보를 위해 MLOps를 통해 노력해야 합니다. MLOps\n",
            "\n",
            "🔹 질문: Explainable AI (XAI, 설명 가능한 AI)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 설명 가능한 AI(Explainable AI, XAI)는 인공지능의 결정 과정과 결과를 이해할 수 있도록 도와주는 기술입니다. 이는 사용자들이 AI의 결정이 어떻게 이루어졌는지, 어떤 요소가 영향을 미쳤는지를 알 수 있게 해줍니다. XAI의 목적은 AI 모델의 투명성을 높이고, 신뢰성을 강화하여 사용자가 쉽게 수용할 수 있도록 하는 것입니다. 특히 의료, 금융, 자율주행 차량 등 신뢰성이 중요한 분야에서 XAI의 필요성이 더욱 두드러집니다. 따라서 설명 가능한 AI는 인간과 AI 간의 협력 관계를 더욱 원활하게 만드는 데 중요한 역할을 합니다.\n",
            "🔹 모델 응답: Explainable AI (XAI, 설명 가능한 AI)이 무엇인지 설명해줘Question: Explainable AI (XAI, 설명 가능한 AI)는 딥러닝 모델의 성능을 설명하는 기술입니다. 이를 통해 모델의 성능을 개선하고 모델이 무엇인지 설명해줘 Request: Explainable AI (XAI, 설명 가능한 AI)는 딥러닝 모델의 성능을 설명하는 기술입니다. 이를 통해 모델의 정확도, 손실 함수, 경량화된 모델, 그리고 기타 중요한 성능 지표를 이해할 수 있습니다. 이를 통해 모델의 성능을 개선할 수 있습니다. 모델의 성능을 설명하는 데 사용되는 기술로, 설명 가능한 AI는 딥러닝, 머신러닝, 인공지능, 그리고 데이터 Science의 여러 분야에서 활용됩니다. 이를 통해 데이터 분석, 의료, 금융, 그리고 다른 분야에서 사용됩니다. XAI는 데이터 과학자, 데이터 분석가, 심리학자, 의사 등 다양한 분야에서 중요한 역할을 합니다. 이를 통해 AI는 더 나은 의사결정에 기여하고, 더 나은 인공지능 시스템을 개발하는 데 기여합니다. Explainable AI는 AI와 데이터 Science의 발전에 기여하고, 인공지능의 적용\n",
            "\n",
            "🔹 질문: 시계열 분석 (Time Series Analysis)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 시계열 분석은 시간에 따라 변화하는 데이터를 분석하는 방법입니다. 이 분석은 과거 데이터를 기반으로 미래의 값을 예측하는 데 주로 사용됩니다. 보통 주식 가격, 기온 변화, 판매량 등과 같은 데이터에 적용됩니다. 시계열 데이터는 시간 순서가 중요하므로, 시계열 모델링에서는 자기상관, 계절성, 추세와 같은 요소를 고려합니다. 이를 통해 데이터의 패턴을 파악하고, 효율적인 의사결정을 지원할 수 있습니다.\n",
            "🔹 모델 응답: 시계열 분석 (Time Series Analysis)이 무엇인지 설명해줘\\n시계열 분석(Time Series Analysis)는 주어진 데이터의 시간에 따른 변화를 분석하는 방법입니다. 주로 시간-series 데이터를 사용하여 시간의 흐름에 따라 변화를 설명하는 데 사용됩니다. 이를 통해 데이터의 패턴이나 관계를 파악하는 데 유용합니다. 시계열 분석은 주로 머신러닝, 통계학, 경제학, 물리학 등 다양한 분야에서 활용됩니다. 시간-series 데이터는 주로 시계열 데이터, 주기적 데이터, 혹은 비주기적 데이터로 나뉩니다. 시계열 분석은 데이터의 패턴이나 관계를 파악하는 데 유용하며, 이를 통해 데이터를 분석하는 데 도움을 줍니다. 시계열 분석은 데이터 분석의 한 분야로, 주로 데이터의 패턴이나 관계를 파악하는 데 사용됩니다. 이를 통해 데이터의 패턴이나 관계를 설명하고, 데이터를 활용하여 새로운 결론을 도출할 수 있습니다. 시계열 분석은 데이터의 특징을 분석하고, 이를 통해 데이터를 활용하여 데이터를 처리하는 데 도움을 줍니다. 시계열 분석은 데이터의 패턴이나 관계를 파악하고\n",
            "\n",
            "🔹 질문: 오픈소스 프레임워크 (TensorFlow, PyTorch)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: 오픈소스 프레임워크는 개발자들이 소스 코드를 자유롭게 사용, 변경 및 배포할 수 있도록 허용하는 소프트웨어입니다. TensorFlow와 PyTorch는 특히 머신러닝과 딥러닝 분야에서 널리 사용되는 오픈소스 프레임워크입니다. TensorFlow는 구글에 의해 개발되었으며, 대규모 모델을 훈련하는 데 강점을 가지고 있습니다. 반면, PyTorch는 페이스북에서 개발되어 직관적인 코드 작성과 빠른 프로토타이핑에 적합합니다. 두 프레임워크 모두 커뮤니티의 활발한 지원을 받아 많은 라이브러리와 도구들이 개발되고 있습니다.\n",
            "🔹 모델 응답: 오픈소스 프레임워크 (TensorFlow, PyTorch)이 무엇인지 설명해줘\n",
            "오픈소스 프레임워크 (Open Source Framework)는 컴퓨터 비전, 머신러닝, 딥러닝 등 다양한 분야에서 활용되는 프레임워크로, 구글에서 개발하고 있습니다. 이 프레임워크는 Python, C++, Java, and others to support various programming languages. TensorFlow is a popular example of an open source framework. It is used for deep learning, image processing, and other machine learning applications. TensorFlow is developed by the Google Brain team. The framework is free to use, and it is open source. TensorFlow has a large community of developers and users. It is a powerful and flexible framework that is used by many research institutions and companies. TensorFlow is also available for mobile devices. This allows users to use the framework on their smartphones and tablets. TensorFlow is a powerful tool that can help researchers and developers in their work. It is an open source framework that is free to use, and it is powerful and flexible. TensorFlow has a large community of developers and users. It is a great tool for those who want to use machine learning and deep learning. TensorFlow is a great tool for those who want to use machine learning and deep learning. It is an open source framework that is free to use, and\n",
            "\n",
            "🔹 질문: ONNX (Open Neural Network Exchange)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: ONNX(Open Neural Network Exchange)는 다양한 딥러닝 프레임워크 간의 상호 운용성을 촉진하기 위한 오픈 소스 형식입니다. 이 포맷을 사용하면, 한 프레임워크에서 학습된 모델을 다른 프레임워크로 쉽게 변환하고 사용할 수 있습니다. ONNX는 주로 PyTorch, TensorFlow, Caffe2와 같은 인기 있는 딥러닝 라이브러리와 호환됩니다. 모델의 표준화된 표현 덕분에 개발자들은 다양한 플랫폼과 툴에서 동일한 모델을 활용할 수 있습니다. 이를 통해 연구자와 엔지니어는 더 효율적으로 작업할 수 있으며, 딥러닝 모델의 배포와 운영이 한층 수월해집니다.\n",
            "🔹 모델 응답: ONNX (Open Neural Network Exchange)이 무엇인지 설명해줘\n",
            "ONNX (Open Neural Network Exchange)는 딥러닝 (Deep Learning)과 머신러닝 (Machine Learning)에서 사용되는 데이터셋의 표준화된 형태로 데이터를 저장하고 공유하는 프로토콜입니다. ONNX은 주로 딥러닝 모델을 작성하고 평가하는 데 유용하며, 이를 통해 다양한 딥러닝 모델을 비교하고 평가할 수 있습니다. ONNX는 또한 데이터셋을 다른 딥러닝 모델과 비교하여 성능을 개선하는 데 도움을 줍니다. ONNX는 또한 데이터셋을 여러 계층에 분할하여 모델을 학습하는 데 유용하며, 이는 각 계층에 맞춘 모델을 생성하는 데 시간을 절약하는 데 유리합니다. ONNX는 또한 딥러닝 모델의 변형을 쉽게 만들 수 있도록 도와줍니다. ONNX는 구글, 파파고, 카카오, 딥러닝 커뮤니티 등 다양한 분야에서 사용되고 있습니다. ONNX는 또한 다양한 소프트웨어와 서비스에서 활용됩니다. ONNX는 또한 딥러닝 데이터셋을 쉽게 수용하고, 분석하고 학습\n",
            "\n",
            "🔹 질문: AutoML (자동화 머신러닝)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: AutoML(자동화 머신러닝)은 머신러닝 모델을 자동으로 생성하고 최적화하는 프로세스를 의미합니다. 이를 통해 비전문가도 데이터 분석과 머신러닝의 복잡한 과정을 쉽게 수행할 수 있습니다. AutoML은 데이터 전처리, 모델 선택, 하이퍼파라미터 튜닝 등의 과정을 자동화하여 효율성을 높입니다. 다양한 AutoML 도구와 플랫폼이 존재하며, 사용자는 이를 활용하여 빠르게 모델을 개발하고 배포할 수 있습니다. 궁극적으로 AutoML은 데이터 사이언스의 접근성을 높이고, 더 많은 사람들이 머신러닝 기술을 활용할 수 있도록 돕는 역할을 합니다.\n",
            "🔹 모델 응답: AutoML (자동화 머신러닝)이 무엇인지 설명해줘\"AutoML\"은 머신러닝 (Machine Learning, ML)이 무엇인지 설명해줘 AutoML은 머신러닝 모델을 자동으로 학습, 훈련, 그리고 평가하는 기술입니다. 이 기술은 머신러닝 데이터셋을 활용하여 모델을 학습하고, 모델 성능을 평가하는 데 도움을 줍니다. AutoML은 데이터 Scientist, 데이터 엔지니어, 그리고 데이터 분석가 모두에게 사용될 수 있습니다. 이 기술은 머신러닝의 발전을 촉진시키고, 데이터 과학자와 머신러닝 엔지니어의 협업을 활성화합니다. AutoML은 또한 데이터 분석, 데이터 마케팅, 의료, 이미지 처리 등 다양한 분야에서 활용됩니다. 최근에는 AutoML의 응용 분야가 크게 확대되고 있습니다. AutoML은 데이터 분석, 머신러닝, 의료, 이미지 처리, 추천 시스템, 추천 시스템 등 다양한 분야에서 활용됩니다. 이를 통해 머신러닝 기술이 더 효과적으로 사용될 수 있습니다. AutoML은 데이터 과학자와 데이터 분석가에게 더 많은 시간을 할애할 수 있게 해줍니다. 이를 통해 데이터\n",
            "\n",
            "🔹 질문: AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘\n",
            "\n",
            "🔹 응답: AI 모델 배포는 개발된 인공지능 모델을 실제 운영 환경에 적용하여 사용자나 다른 시스템이 활용할 수 있도록 하는 과정입니다. 이 과정에는 모델을 서버에 설치하고, API를 통해 접근할 수 있도록 설정하는 작업이 포함됩니다. 또한, 성능 모니터링과 유지보수를 통해 모델의 효율성을 지속적으로 관리하는 것이 중요합니다. 배포된 모델은 데이터를 실시간으로 처리하고, 예측 결과를 제공하여 다양한 비즈니스 문제를 해결하는 데 기여합니다. 마지막으로, 배포 후에는 사용자 피드백을 받아 모델을 개선하는 과정도 필요합니다.\n",
            "🔹 모델 응답: AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해줘# AI 모델 배포 (AI Model Deployment)이 무엇인지 설명해�\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = compute_metrics(generated_responses, outputs)\n",
        "\n",
        "print(\"\\n📊 Evaluation Metrics:\")\n",
        "print(f\"🔹 BLEU Score: {metrics['bleu']:.4f}\")\n",
        "print(f\"🔹 ROUGE-1: {metrics['rouge1']:.4f}\")\n",
        "print(f\"🔹 ROUGE-2: {metrics['rouge2']:.4f}\")\n",
        "print(f\"🔹 ROUGE-L: {metrics['rougeL']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Z-QUVPuCro",
        "outputId": "b44ae407-1fc3-456a-ed79-497ad2aa72aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Evaluation Metrics:\n",
            "🔹 BLEU Score: 0.0484\n",
            "🔹 ROUGE-1: 0.3602\n",
            "🔹 ROUGE-2: 0.2820\n",
            "🔹 ROUGE-L: 0.3641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "- 1) Bleu 가 0.02에서 0.04로 증가한 것은 확인이 됩니다. 또한 훈련에서도 정상적으로 overfitting이 일어난 것을 확인할 수 있습니다.\n",
        "\n",
        "- 2) 단, Rouge score는 오히려 하락한 것이 확인이 됩니다.\n",
        "\n",
        "- 3) 출력의 형태는 육안으로 보았을 때 훨씬 나아진 것을 확인할 수 있습니다.\n",
        "\n",
        "- 4) 이번 프로젝트의 목표는 해당 방식으로 훈련을 하여 aws에 모델을 올려 논문 요약 챗봇에 장착하는 것입니다."
      ],
      "metadata": {
        "id": "0TjYsbqo7UxS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DENcGyZ0LME"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}