{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import chardet\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "path = kagglehub.dataset_download(\"debasisdotcom/name-entity-recognition-ner-dataset\")\n",
    "dir = Path(path)\n",
    "path_lst = [path for path in dir.rglob('*')]\n",
    "data_path = path_lst[0]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open(data_path, 'rb') as file:\n",
    "    encoding = chardet.detect(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=2e-5\n",
    "per_device_train_batch_size=16\n",
    "per_device_eval_batch_size=16\n",
    "num_train_epochs=2\n",
    "weight_decay=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋입니다.\n",
    "df = pd.read_csv(data_path, encoding='Windows-1252')\n",
    "# ner과 pos에 대한 설명이 있는 파일입니다. \n",
    "ner_df = pd.read_csv(\"data/NER_tags.csv\")\n",
    "ner_unique = list(ner_df['NER 태그'][1:].apply(lambda x: x.split('-')[1]).unique())\n",
    "ner_unique.append(\"O\")\n",
    "index_result = []\n",
    "for unique_tag in ner_unique:\n",
    "    for i, tag in enumerate(ner_df['NER 태그'].to_list()):\n",
    "        if len(tag) > 1 and unique_tag==tag.split('-')[1]:\n",
    "            index_result.append(i)\n",
    "\n",
    "        elif len(tag) == 1 and unique_tag==tag:\n",
    "            index_result.append(i)\n",
    "        \n",
    "\n",
    "ner_df = ner_df.iloc[index_result].reset_index(drop=True)\n",
    "pos_df = pd.read_csv(\"data/POS_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER 태그</th>\n",
       "      <th>설명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-geo</td>\n",
       "      <td>위치(지리적 개체)의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-geo</td>\n",
       "      <td>위치(지리적 개체)의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-tim</td>\n",
       "      <td>시간 표현의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-tim</td>\n",
       "      <td>시간 표현의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-org</td>\n",
       "      <td>조직(Organization)의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-org</td>\n",
       "      <td>조직(Organization)의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-per</td>\n",
       "      <td>사람(Person)의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-per</td>\n",
       "      <td>사람(Person)의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B-gpe</td>\n",
       "      <td>정치적/지리적 단위의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-gpe</td>\n",
       "      <td>정치적/지리적 단위의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B-art</td>\n",
       "      <td>예술 작품의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-art</td>\n",
       "      <td>예술 작품의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B-eve</td>\n",
       "      <td>이벤트(이벤트)의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-eve</td>\n",
       "      <td>이벤트(이벤트)의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B-nat</td>\n",
       "      <td>자연 개체(Natural entity)의 시작</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I-nat</td>\n",
       "      <td>자연 개체(Natural entity)의 내부</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>기타(Non-entity)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NER 태그                         설명\n",
       "0   B-geo             위치(지리적 개체)의 시작\n",
       "1   I-geo             위치(지리적 개체)의 내부\n",
       "2   B-tim                  시간 표현의 시작\n",
       "3   I-tim                  시간 표현의 내부\n",
       "4   B-org       조직(Organization)의 시작\n",
       "5   I-org       조직(Organization)의 내부\n",
       "6   I-per             사람(Person)의 내부\n",
       "7   B-per             사람(Person)의 시작\n",
       "8   B-gpe             정치적/지리적 단위의 시작\n",
       "9   I-gpe             정치적/지리적 단위의 내부\n",
       "10  B-art                  예술 작품의 시작\n",
       "11  I-art                  예술 작품의 내부\n",
       "12  B-eve               이벤트(이벤트)의 시작\n",
       "13  I-eve               이벤트(이벤트)의 내부\n",
       "14  B-nat  자연 개체(Natural entity)의 시작\n",
       "15  I-nat  자연 개체(Natural entity)의 내부\n",
       "16      O             기타(Non-entity)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS 태그</th>\n",
       "      <th>설명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>단수 일반 명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NNP</td>\n",
       "      <td>단수 고유 명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>전치사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>한정사(관사)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JJ</td>\n",
       "      <td>형용사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NNS</td>\n",
       "      <td>복수 일반 명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>마침표</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VBD</td>\n",
       "      <td>과거형 동사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,</td>\n",
       "      <td>쉼표</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VBN</td>\n",
       "      <td>과거분사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>3인칭 단수 현재형 동사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CD</td>\n",
       "      <td>숫자(Cardinal Number)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VB</td>\n",
       "      <td>원형 동사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CC</td>\n",
       "      <td>등위접속사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RB</td>\n",
       "      <td>부사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VBG</td>\n",
       "      <td>동명사 또는 현재분사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VBP</td>\n",
       "      <td>현재형 동사(복수 주어와 함께 사용)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRP</td>\n",
       "      <td>대명사(예: he, she, it)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>POS</td>\n",
       "      <td>소유격 표지(예: 's)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRP$</td>\n",
       "      <td>소유격 대명사(예: my, your)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MD</td>\n",
       "      <td>조동사(예: can, will)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>``</td>\n",
       "      <td>여는 따옴표</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WDT</td>\n",
       "      <td>관계 한정사(예: which, that)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JJS</td>\n",
       "      <td>최상급 형용사(예: best)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JJR</td>\n",
       "      <td>비교급 형용사(예: better)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WP</td>\n",
       "      <td>의문 대명사(예: who, what)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NNPS</td>\n",
       "      <td>복수 고유 명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RP</td>\n",
       "      <td>소사(동사와 함께 쓰이는 부사)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WRB</td>\n",
       "      <td>의문 부사(예: where, when)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>$</td>\n",
       "      <td>화폐 기호(예: $)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RBR</td>\n",
       "      <td>비교급 부사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>:</td>\n",
       "      <td>콜론</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RRB</td>\n",
       "      <td>닫는 괄호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LRB</td>\n",
       "      <td>여는 괄호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EX</td>\n",
       "      <td>존재 구문(it there is)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RBS</td>\n",
       "      <td>최상급 부사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>;</td>\n",
       "      <td>세미콜론</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PDT</td>\n",
       "      <td>전치한정사(예: all, such)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WP$</td>\n",
       "      <td>소유격 의문 대명사(예: whose)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UH</td>\n",
       "      <td>감탄사(예: oh, wow)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FW</td>\n",
       "      <td>외래어</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS 태그                      설명\n",
       "0      NN                단수 일반 명사\n",
       "1     NNP                단수 고유 명사\n",
       "2      IN                     전치사\n",
       "3      DT                 한정사(관사)\n",
       "4      JJ                     형용사\n",
       "5     NNS                복수 일반 명사\n",
       "6       .                     마침표\n",
       "7     VBD                  과거형 동사\n",
       "8       ,                      쉼표\n",
       "9     VBN                    과거분사\n",
       "10    VBZ           3인칭 단수 현재형 동사\n",
       "11     CD     숫자(Cardinal Number)\n",
       "12     VB                   원형 동사\n",
       "13     CC                   등위접속사\n",
       "14     TO                      to\n",
       "15     RB                      부사\n",
       "16    VBG             동명사 또는 현재분사\n",
       "17    VBP    현재형 동사(복수 주어와 함께 사용)\n",
       "18    PRP     대명사(예: he, she, it)\n",
       "19    POS           소유격 표지(예: 's)\n",
       "20   PRP$    소유격 대명사(예: my, your)\n",
       "21     MD       조동사(예: can, will)\n",
       "22     ``                  여는 따옴표\n",
       "23    WDT  관계 한정사(예: which, that)\n",
       "24    JJS        최상급 형용사(예: best)\n",
       "25    JJR      비교급 형용사(예: better)\n",
       "26     WP    의문 대명사(예: who, what)\n",
       "27   NNPS                복수 고유 명사\n",
       "28     RP       소사(동사와 함께 쓰이는 부사)\n",
       "29    WRB   의문 부사(예: where, when)\n",
       "30      $             화폐 기호(예: $)\n",
       "31    RBR                  비교급 부사\n",
       "32      :                      콜론\n",
       "33    RRB                   닫는 괄호\n",
       "34    LRB                   여는 괄호\n",
       "35     EX      존재 구문(it there is)\n",
       "36    RBS                  최상급 부사\n",
       "37      ;                    세미콜론\n",
       "38    PDT     전치한정사(예: all, such)\n",
       "39    WP$    소유격 의문 대명사(예: whose)\n",
       "40     UH         감탄사(예: oh, wow)\n",
       "41     FW                     외래어"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(ner_df[['NER 태그','설명']])\n",
    "print()\n",
    "display(pos_df[['POS 태그','설명']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "id2label = {index: value for index, value in ner_df['NER 태그'].items()}\n",
    "label2id = {value: index for index, value in ner_df['NER 태그'].items()}\n",
    "label_list = list(label2id.keys())\n",
    "df['Tag'] = df['Tag'].apply(lambda x: label2id[x] if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.016203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.846776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     proportion\n",
       "Tag            \n",
       "0      0.035900\n",
       "1      0.007071\n",
       "2      0.019391\n",
       "3      0.006226\n",
       "4      0.019210\n",
       "5      0.016006\n",
       "6      0.016452\n",
       "7      0.016203\n",
       "8      0.015135\n",
       "9      0.000189\n",
       "10     0.000383\n",
       "11     0.000283\n",
       "12     0.000294\n",
       "13     0.000241\n",
       "14     0.000192\n",
       "15     0.000049\n",
       "16     0.846776"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16번 태그(기타)가 84% 이상임을 알 수 있다.\n",
    "# 따라서 모델 설계를 해서 metric이 84$ 이상 나와야 유효한 모델임을 유추할 수 있다.\n",
    "# 모두 16번만 찍어도 84%가 accuracy로 찍히는 라벨 불균형 상태이기 때문이다.\n",
    "proportin_df = pd.DataFrame(df['Tag'].value_counts(normalize=True).sort_index())\n",
    "display(proportin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, ModernBertModel\n",
    "import torch\n",
    "model_id = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id, \n",
    "    num_labels=len(label_list), \n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    "    )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "index_lst = [i for i, row in df.iterrows() if not pd.isna(row['Sentence #'])]\n",
    "\n",
    "index_lst = np.array(df[~df['Sentence #'].apply(lambda x: pd.isna(x))].index)\n",
    "index_lst = np.append(index_lst, len(df))\n",
    "start_index = index_lst[:-1]\n",
    "end_index = index_lst[1:]\n",
    "\n",
    "result = []\n",
    "for start, end in zip(start_index, end_index):\n",
    "    data = df.iloc[start:end]\n",
    "    result.append(data)\n",
    "    \n",
    "x_list = []\n",
    "y_list = []\n",
    "for data in result:\n",
    "    token_lst = data['Word'].to_list()\n",
    "    label_lst = data['Tag'].to_list()\n",
    "    if not (any(pd.isnull(x) for x in token_lst) or any(pd.isnull(x) for x in label_lst)):\n",
    "        x_list.append(token_lst)\n",
    "        y_list.append(label_lst)\n",
    "index_lst = list(range(len(x_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'ner_tags'],\n",
       "    num_rows: 47949\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, Features, Value, Sequence\n",
    "\n",
    "dataset_dict = {\n",
    "    'id': index_lst,\n",
    "    'tokens': x_list,\n",
    "    'ner_tags': y_list,\n",
    "}\n",
    "dataset = Dataset.from_dict(dataset_dict)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3c8100df9f4a849cbf0b8ac06aebd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 47949\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # samples의 첫번째는 토큰이 29개입니다. 따라서 라벨도 29개가 나와야 합니다.\n",
    "    samples = examples\n",
    "\n",
    "    # 첫번째 샘플의 input_ids의 수는 41입니다. 즉 토큰화된 것을 한 번 더 토크나이징 하는 것입니다. \n",
    "    tokenized_inputs  = tokenizer(samples['tokens'], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(samples['ner_tags']):\n",
    "\n",
    "        # 한 문장 내에서 토큰이 몇 번째 단어에 매핑되는지 알려줍니다. \n",
    "        # None은 CLS와 SEP으로 매핑됩니다.\n",
    "        # input_ids의 수가 41이기 때문에, 라벨 또한 41로 늘려야 합니다. \n",
    "        # 현재는 29개이기 때문에 아래의 logic을 거치는 것입니다.\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index = i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        # 아래 로직은 다음 역할을 합니다.\n",
    "        # cls와 sep엔 -100을 부여합니다.\n",
    "        # 한 단어에서 잘려나온 토큰에 대해선 첫 번째 토큰을 제외한 나머지 토큰에 대해 -100을 부여합니다.\n",
    "        # 그 외의 모든 토큰에 대해선 라벨 값을 그대로 사용합니다.\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 37543\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5611\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4795\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_test_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_val_dataset = train_val_test_split['train']\n",
    "test_dataset = train_val_test_split['test']\n",
    "\n",
    "train_val_split = train_val_dataset.train_test_split(test_size=0.13)\n",
    "train_dataset = train_val_split['train']\n",
    "val_dataset = train_val_split['test']\n",
    "\n",
    "dataset_input = DatasetDict({\n",
    "    'train':train_dataset,\n",
    "    'val':val_dataset,\n",
    "    'test':test_dataset,\n",
    "})\n",
    "dataset_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = [label_list[i] for i in dataset_input['train'][0][f\"ner_tags\"]]\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels,  zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch._dynamo\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\".results/week3_advanced_ner\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=dataset_input[\"train\"],\n",
    "    eval_dataset=dataset_input[\"val\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4694' max='4694' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4694/4694 05:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.111187</td>\n",
       "      <td>0.799516</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.806967</td>\n",
       "      <td>0.965679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.104038</td>\n",
       "      <td>0.813069</td>\n",
       "      <td>0.819338</td>\n",
       "      <td>0.816192</td>\n",
       "      <td>0.967587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paradeigma/workspace/python/sparta_coding/.env/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4694, training_loss=0.12815557015820875, metrics={'train_runtime': 316.9642, 'train_samples_per_second': 236.891, 'train_steps_per_second': 14.809, 'total_flos': 855214290355218.0, 'train_loss': 0.12815557015820875, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paradeigma/workspace/python/sparta_coding/.env/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[[-9.65326801e-02, -1.36011994e+00,  4.81627643e-01, ...,\n",
      "         -1.18671012e+00, -2.15134573e+00,  7.33527184e+00],\n",
      "        [-6.43327653e-01, -1.35887873e+00,  9.41215232e-02, ...,\n",
      "         -1.37261772e+00, -2.08675838e+00,  9.89927578e+00],\n",
      "        [-8.28978539e-01, -1.22003126e+00, -2.02378854e-01, ...,\n",
      "         -1.42313635e+00, -2.02780652e+00,  1.01041059e+01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 6.39653146e-01, -1.44535923e+00,  6.84136450e-01, ...,\n",
      "         -1.29861951e+00, -2.17158294e+00,  6.30365181e+00],\n",
      "        [-1.18354425e-01, -1.61225247e+00, -5.10575771e-02, ...,\n",
      "         -1.71619093e+00, -2.30084205e+00,  9.69075871e+00],\n",
      "        [-4.88178432e-01, -1.30353630e+00, -1.80001184e-01, ...,\n",
      "         -1.95208001e+00, -2.26285100e+00,  9.99471283e+00],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 1.11311868e-01, -1.40398014e+00,  1.10396981e+00, ...,\n",
      "         -1.29468989e+00, -2.03127384e+00,  6.82918501e+00],\n",
      "        [-5.52765250e-01, -1.63004327e+00,  1.16616702e+00, ...,\n",
      "         -1.28769243e+00, -2.03937340e+00,  9.65436840e+00],\n",
      "        [-1.20581877e+00, -2.13311052e+00,  3.09420562e+00, ...,\n",
      "         -1.53155196e+00, -2.11157632e+00,  8.79055023e+00],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 4.60322678e-01, -1.42926919e+00,  1.16208982e+00, ...,\n",
      "         -1.26429498e+00, -2.17717743e+00,  6.69504356e+00],\n",
      "        [ 3.50298911e-01, -1.73170841e+00,  2.74934697e+00, ...,\n",
      "         -1.55217934e+00, -2.48899913e+00,  9.06895733e+00],\n",
      "        [-1.25824198e-01, -1.36766863e+00,  8.33376122e+00, ...,\n",
      "         -1.10695422e+00, -1.10124731e+00,  4.62716937e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 5.46968937e-01, -1.55641246e+00,  6.16350234e-01, ...,\n",
      "         -1.45140171e+00, -2.09021735e+00,  6.36102200e+00],\n",
      "        [ 8.83814216e-01, -1.55686474e+00, -1.11877799e+00, ...,\n",
      "         -5.05536914e-01, -1.19488668e+00,  7.60076642e-02],\n",
      "        [ 6.18379176e-01, -3.65200371e-01, -1.22835469e+00, ...,\n",
      "         -1.95016003e+00, -2.20441794e+00,  1.20749044e+00],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]],\n",
      "\n",
      "       [[ 5.67568779e-01, -1.23276842e+00,  4.33589160e-01, ...,\n",
      "         -1.35454762e+00, -2.16561985e+00,  6.39990854e+00],\n",
      "        [ 9.03062403e-01, -1.40779197e+00, -7.46549249e-01, ...,\n",
      "         -1.77229917e+00, -2.67612934e+00,  9.12646866e+00],\n",
      "        [-2.72035331e-01, -8.94722283e-01, -1.48293018e+00, ...,\n",
      "         -8.94170940e-01, -1.00016856e+00,  6.77015245e-01],\n",
      "        ...,\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02],\n",
      "        [-1.00000000e+02, -1.00000000e+02, -1.00000000e+02, ...,\n",
      "         -1.00000000e+02, -1.00000000e+02, -1.00000000e+02]]],\n",
      "      dtype=float32), label_ids=array([[-100,   16,   16, ..., -100, -100, -100],\n",
      "       [-100,   16,   16, ..., -100, -100, -100],\n",
      "       [-100,   16,   16, ..., -100, -100, -100],\n",
      "       ...,\n",
      "       [-100,   16,    2, ..., -100, -100, -100],\n",
      "       [-100,    7, -100, ..., -100, -100, -100],\n",
      "       [-100,   16,    8, ..., -100, -100, -100]]), metrics={'test_loss': 0.1077246442437172, 'test_precision': 0.8076473234367971, 'test_recall': 0.8128395508873597, 'test_f1': 0.8102351189133085, 'test_accuracy': 0.9667079338573307, 'test_runtime': 5.7366, 'test_samples_per_second': 835.854, 'test_steps_per_second': 52.295})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "metrics = trainer.predict(dataset_input[\"test\"])\n",
    "pprint(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
