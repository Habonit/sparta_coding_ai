{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_950/3175900557.py:15: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Title: How Do Large Language Models Acquire Factual Knowledge During Pretraining?\n",
      "📝 Authors: Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo\n",
      "📅 Submitted: 2024-06-17 17:54:40+00:00\n",
      "🔗 PDF Link: http://arxiv.org/pdf/2406.11813v3\n",
      "📝 Abstract:\n",
      "Despite the recent observation that large language models (LLMs) can store\n",
      "substantial factual knowledge, there is a limited understanding of the\n",
      "mechanisms of how they acquire factual knowledge through pretraining. This work\n",
      "addresses this gap by studying how LLMs acquire factual knowledge during\n",
      "pretraining. The findings reveal several important insights into the dynamics\n",
      "of factual knowledge acquisition during pretraining. First, counterintuitively,\n",
      "we observe that pretraining on more data shows no significant improvement in\n",
      "the model's capability to acquire and maintain factual knowledge. Next, there\n",
      "is a power-law relationship between training steps and forgetting of\n",
      "memorization and generalization of factual knowledge, and LLMs trained with\n",
      "duplicated training data exhibit faster forgetting. Third, training LLMs with\n",
      "larger batch sizes can enhance the models' robustness to forgetting. Overall,\n",
      "our observations suggest that factual knowledge acquisition in LLM pretraining\n",
      "occurs by progressively increasing the probability of factual knowledge\n",
      "presented in the pretraining data at each step. However, this increase is\n",
      "diluted by subsequent forgetting. Based on this interpretation, we demonstrate\n",
      "that we can provide plausible explanations for recently observed behaviors of\n",
      "LLMs, such as the poor performance of LLMs on long-tail knowledge and the\n",
      "benefits of deduplicating the pretraining corpus.\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "from pathlib import Path\n",
    "## 요약 및 리뷰하려는 논문을 아카이브에서 id를 가져옵니다. \n",
    "## 이후 다운을 받습니다. \n",
    "def download_arxiv_pdf(pdf_url, save_path):\n",
    "    response = requests.get(pdf_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "\n",
    "arxiv_id = \"2406.11813\"\n",
    "search = arxiv.Search(id_list=[arxiv_id])\n",
    "for result in search.results():\n",
    "    break\n",
    "save_path = Path('references') / f\"0-{result.title[:15]}.pdf\"\n",
    "pdf_url = result.pdf_url\n",
    "download_arxiv_pdf(pdf_url, save_path)\n",
    "\n",
    "print(f\"📌 Title: {result.title}\")\n",
    "print(f\"📝 Authors: {', '.join([author.name for author in result.authors])}\")\n",
    "print(f\"📅 Submitted: {result.published}\")\n",
    "print(f\"🔗 PDF Link: {result.pdf_url}\")\n",
    "print(f\"📝 Abstract:\\n{result.summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "# 여기는 손수 정리해줘야 합니다.\n",
    "# 논문을 section 별로 나누는 것입니다.\n",
    "\n",
    "loader = UnstructuredPDFLoader(save_path)\n",
    "documents = loader.load()\n",
    "output = {\n",
    "    \"Title\":result.title,\n",
    "    \"Authors\":'\\n'.join([author.name for author in result.authors]),\n",
    "    \"Submitted\":str(result.published),\n",
    "    \"Abstract\":result.summary,\n",
    "    # 아래는 논문의 reference 인용 횟수를 count하기 위한 기초 작업입니다.\n",
    "    \"Introduction\":documents[0].page_content.split(\"Introduction\\n\\n\")[-1].split(\"Related Work\\n\\n\")[0],\n",
    "    \"Related Work\":documents[0].page_content.split(\"Related Work\\n\\n\")[-1].split(\"Experimental Setup\\n\\n\")[0],\n",
    "    \"Experimental Setup\":documents[0].page_content.split(\"Experimental Setup\\n\\n\")[-1].split(\"Results\\n\\n\")[0],\n",
    "    \"Results\":documents[0].page_content.split(\"Results\\n\\n\")[-1].split(\"Discussion and Conclusions\\n\\n\")[0],\n",
    "    \"Discussion and Conclusions\":documents[0].page_content.split(\"Discussion and Conclusions\\n\\n\")[-1].split(\"References\\n\\n\")[0],\n",
    "    \"References\":documents[0].page_content.split(\"References\\n\\n\")[-1].split(\"Appendix\\n\\n\")[0],\n",
    "    \"Appendix\":documents[0].page_content.split(\"Appendix\\n\\n\")[-1],\n",
    "}\n",
    "reference_count_keys = [\"Introduction\", \"Related Work\", \"Experimental Setup\", \"Results\", \"Discussion and Conclusions\"]\n",
    "content_keys = [\"Title\",\"Authors\",\"Submitted\",\"Abstract\",\"Introduction\", \"Related Work\", \"Experimental Setup\", \"Results\", \"Discussion and Conclusions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\\n\" 사이의 문자가 threshold 미만이면 제거합니다.\n",
    "threshold = 25\n",
    "\n",
    "for key in reference_count_keys:\n",
    "    result = []\n",
    "    for text in output[key].split(\"\\n\"):\n",
    "        if len(text) >= threshold:\n",
    "            result.append(text)\n",
    "    output[key] = \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# .env가 아닌 config.env에서 환경 변수 로드\n",
    "load_dotenv(dotenv_path=\"config.env\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "def message_to_openai(user, model = 'gpt-4o-mini'):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        store=True,\n",
    "        messages=[{\"role\": \"user\", \"content\": user}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response\n",
    "\n",
    "user_prompt_template = \"\"\"\n",
    "논문: {essay}\n",
    "\n",
    "다음 논문의 내용을 요약해주세요. 항목은 다음과 같습니다.\n",
    "\n",
    "## 항목 정보\n",
    "1. 기본 정보: 논문의 제목과 저자, 모두 영문으로 작성합니다. \n",
    "2. 연구 목적: 이 논문이 가진 문제의식과 이에 대한 설명을 작성합니다. 이때 문제의식은 명사형으로 끝내고 설명은 300자에서 500자로 서술합니다. \n",
    "3. 연구 방법: 해당 논문이 연구한 실험 방법과 데이터, 모델, 분석 방법 등을 작성합니다. 연구 방법은 가능한 한 구체적으로 기술합니다.\n",
    "4. 주요 결과: 논문의 연구 성과를 요약합니다. 이때 연구의 핵심적인 발견과 논문의 주요 기여를 강조합니다.\n",
    "5. 결론 및 시사점: 논문의 결론과 연구의 의미를 정리합니다. 또한 연구의 한계점과 향후 연구 방향을 포함하여 설명합니다.\n",
    "\n",
    "## 응답 예시\n",
    "\n",
    "### 1. 기본 정보\n",
    "1) 제목: <<논문 제목(영문)>>\n",
    "2) 저자: <<논문 저자(영문)>>\n",
    "\n",
    "### 2. 연구 목적\n",
    "1) 문제의식: <<문제 의식을 명사형으로 구성>>\n",
    "2) 설명: <<문제 의식에 대한 설명을 300자에서 500자로 서술>>\n",
    "\n",
    "### 3. 연구 방법\n",
    "1) 실험 방법: <<연구에서 사용한 실험 방법을 기술>>\n",
    "2) 데이터: <<사용된 데이터의 출처 및 특성을 설명>>\n",
    "3) 모델 및 분석 방법: <<적용된 모델과 분석 기법을 설명>>\n",
    "\n",
    "### 4. 주요 결과\n",
    "1) 연구의 주요 발견: <<논문의 핵심 결과를 요약>>\n",
    "2) 기여 및 성과: <<연구가 기존 연구 대비 기여한 점을 설명>>\n",
    "\n",
    "### 5. 결론 및 시사점\n",
    "1) 결론: <<연구의 주요 결론을 요약>>\n",
    "2) 시사점: <<연구가 시사하는 바와 활용 가능성을 설명>>\n",
    "3) 연구의 한계: <<논문에서 언급한 연구의 한계를 기술>>\n",
    "4) 향후 연구 방향: <<추가 연구가 필요한 부분을 설명>>\n",
    "\n",
    "가능한 한 논문의 핵심 내용을 유지하면서 간결하고 명확하게 요약해주세요.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = \"\\n\\n\".join([output[key] for key in content_keys])\n",
    "user_message = user_prompt_template.format(essay=essay)\n",
    "response = message_to_openai(user_message)\n",
    "output['Basic_summary'] = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. 기본 정보\n",
      "1) 제목: How Do Large Language Models Acquire Factual Knowledge During Pretraining?\n",
      "2) 저자: Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo\n",
      "\n",
      "### 2. 연구 목적\n",
      "1) 문제의식: 대형 언어 모델의 사실적 지식 습득 메커니즘\n",
      "2) 설명: 최근 대형 언어 모델(LLM)이 상당한 사실적 지식을 저장할 수 있다는 관찰에도 불구하고, 이들이 사전 훈련 중 사실적 지식을 어떻게 습득하는지에 대한 이해는 제한적이다. 본 연구는 LLM의 사실적 지식 습득 과정을 분석하여, 훈련 데이터의 양, 훈련 단계, 모델 크기, 배치 크기 등의 다양한 조건이 지식 습득에 미치는 영향을 조사한다. 이를 통해 LLM의 훈련 동역학을 이해하고, 지식 습득의 메커니즘을 규명하고자 한다.\n",
      "\n",
      "### 3. 연구 방법\n",
      "1) 실험 방법: 연구진은 LLM의 중간 사전 훈련 체크포인트를 사용하여, 이전에 접하지 않은 목표 지식을 주입하고, 다양한 조건에서 사실적 지식의 습득 과정을 모니터링하였다. \n",
      "2) 데이터: FICTIONAL KNOWLEDGE 데이터셋을 구성하여, 허구적이지만 현실적인 개체에 대한 설명을 포함한 문장을 주입하였다. 이 데이터셋은 LLM이 훈련 중에 접하지 않은 지식을 포함한다.\n",
      "3) 모델 및 분석 방법: OLMo 모델을 사용하여, 주입된 지식에 대한 로그 확률을 평가하고, 지식 습득의 효과성 및 유지 가능성을 측정하기 위해 다양한 메트릭을 정의하였다.\n",
      "\n",
      "### 4. 주요 결과\n",
      "1) 연구의 주요 발견: LLM은 사실적 지식을 습득할 때, 미세한 확률의 누적을 통해 이루어지며, 훈련 중 지식이 주어지지 않으면 잊어버리는 경향이 있다. 또한, 모델 크기가 클수록 지식 습득의 효과성이 높아지지만, 훈련 데이터의 양이 많아져도 효과성은 크게 개선되지 않는다.\n",
      "2) 기여 및 성과: 본 연구는 LLM의 사실적 지식 습득 동역학을 세밀하게 분석하고, 데이터 중복 제거와 배치 크기 증가가 지식 습득에 긍정적인 영향을 미친다는 점을 밝혀내어, LLM의 훈련 방법론에 대한 새로운 통찰을 제공한다.\n",
      "\n",
      "### 5. 결론 및 시사점\n",
      "1) 결론: LLM의 사실적 지식 습득은 미세한 확률의 누적을 통해 이루어지며, 잊어버림 현상과의 관계가 중요하다. \n",
      "2) 시사점: 연구 결과는 LLM의 훈련 데이터 구성 및 훈련 방법에 대한 전략적 접근을 제안하며, LLM의 성능 향상에 기여할 수 있다.\n",
      "3) 연구의 한계: 본 연구는 특정 모델과 데이터셋에 국한되어 있으며, 다양한 LLM 아키텍처에 대한 일반화 가능성에 대한 검증이 필요하다.\n",
      "4) 향후 연구 방향: LLM의 지식 습득 메커니즘을 더욱 깊이 이해하기 위해, 다양한 유형의 지식과 훈련 조건을 탐색하는 추가 연구가 필요하다.\n"
     ]
    }
   ],
   "source": [
    "print(output['Basic_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 섹션 별로 2000글자 단위로 쪼갭니다.\n",
    "# 쪼개는 목적은 인용 부를 확인하기 위함입니다.\n",
    "def preprocess(text, title, key, chunk_size=2000, chunk_overlap=0):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap  \n",
    "    )\n",
    "\n",
    "    documents = text_splitter.create_documents([text])\n",
    "\n",
    "    # 각 문서에 메타데이터 추가\n",
    "    for doc in documents:\n",
    "        doc.metadata = {\"Title\": title, \"Key\": key} \n",
    "\n",
    "    return documents\n",
    "\n",
    "for key in reference_count_keys:\n",
    "    output[key] = preprocess(output[key], output['Title'], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_template = \"\"\"\n",
    "다음은 논문에서 reference 부분만 발췌한 것입니다. \n",
    "이를 보고 논문의 제목과 저자를 출력 형식에 따라 JSON 형태로 정리해주세요.\n",
    "\n",
    "References:\n",
    "{references}\n",
    "\n",
    "출력 형식:\n",
    "```json\n",
    "{{\n",
    "1 : {{\"Title\":<<논문의 제목1>>, \"Authors\":<<논문의 저자1>>}},\n",
    "2 : {{\"Title\":<<논문의 제목2>>, \"Authors\":<<논문의 저자2>>}},\n",
    "3 : {{\"Title\":<<논문의 제목3>>, \"Authors\":<<논문의 저자3>>}}\n",
    "}}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "user_message = user_message_template.format(references=output['References'])\n",
    "response = message_to_openai(user_message)\n",
    "\n",
    "text = response.choices[0].message.content\n",
    "text = re.sub(\"```json\",\"\",text)\n",
    "text = re.sub(\"```\",\"\",text)\n",
    "json_data = json.loads(text)\n",
    "\n",
    "reference_dict = {}\n",
    "for key, dict_data in json_data.items():\n",
    "    dict_data['Counter'] = 0\n",
    "    dict_data['Context'] = []\n",
    "    reference_dict[key] = dict_data\n",
    "\n",
    "output['References'] = deepcopy(reference_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_template_dict = {\n",
    "    '0': \"\"\"\n",
    "다음은 논문의 일부와 참고문헌 목록을 정리한 것입니다. \n",
    "논문 본문에서 참고문헌이 인용되었다면, 해당 참고문헌의 \"Counter\"에 인용 횟수를 기록하고,  \n",
    "\"Context\"에는 해당 참고문헌이 인용된 부분을 **300자 이내**로 발췌해서 저장하세요.  \n",
    "**인용되지 않은 참고문헌은 출력하지 말고, 인용된 참고문헌만 JSON 형식으로 출력하세요.**\n",
    "\n",
    "**조건**\n",
    "- 인용 표시: 논문 본문에서 참고문헌이 **[숫자]** 형식 (`[5]`, `[27]` 등)으로 인용된 경우만 추출하세요.\n",
    "- 참고문헌이 여러 번 인용되었을 경우, 각 인용 부분을 `\"Context\"` 배열에 저장하세요.\n",
    "- `\"Context\"`에 포함되는 인용된 문장은 **최대 300자 이내**로 유지하세요.\n",
    "\n",
    "**출력 형식**\n",
    "```json\n",
    "{{\n",
    "    \"27\": {{\n",
    "        \"Title\": \"참고문헌 제목1\",\n",
    "        \"Counter\": 3,\n",
    "        \"Context\": [\"인용된 부분1\", \"인용된 부분2\", \"인용된 부분3\"]\n",
    "    }},\n",
    "    \"5\": {{\n",
    "        \"Title\": \"참고문헌 제목2\",\n",
    "        \"Counter\": 1,\n",
    "        \"Context\": [\"인용된 부분1\"]\n",
    "    }}\n",
    "}}\n",
    "```\n",
    "\n",
    "**References**\n",
    "{references}\n",
    "\n",
    "**Essay**\n",
    "{essay}\n",
    "\n",
    "\"\"\",\n",
    "    \"1\" : \"\"\"\n",
    "논문의 일부와 참고문헌 목록이 제공되었습니다. \n",
    "논문 본문에서 특정 참고문헌이 인용되었다면, 해당 참고문헌의 **인용 횟수**를 `\"Counter\"`에 기록하고, \n",
    "**인용된 문장**을 `\"Context\"`에 최대 300자 이내로 발췌하여 저장하세요.  \n",
    "**한 번도 인용되지 않은 참고문헌은 출력에서 제외됩니다.**\n",
    "\n",
    "## 조건\n",
    "- 인용표시: 본문에서 참고문헌이 **[숫자]** (`[10]`, `[3]` 등) 형식으로 인용된 경우만 포함합니다.\n",
    "- 동일한 참고문헌이 여러 번 인용되면 `\"Context\"` 배열에 모든 인용 부분을 포함합니다.\n",
    "- `\"Context\"`의 개별 항목은 **최대 300자 이하**를 유지해야 합니다.\n",
    "\n",
    "## 출력 예시\n",
    "```json\n",
    "{{\n",
    "    \"10\": {{\n",
    "        \"Title\": \"참고문헌 제목1\",\n",
    "        \"Counter\": 2,\n",
    "        \"Context\": [\"첫 번째 인용 문장\", \"두 번째 인용 문장\"]\n",
    "    }},\n",
    "    \"3\": {{\n",
    "        \"Title\": \"참고문헌 제목2\",\n",
    "        \"Counter\": 1,\n",
    "        \"Context\": [\"인용된 문장\"]\n",
    "    }}\n",
    "}}\n",
    "```\n",
    "\n",
    "## References\n",
    "{references}\n",
    "\n",
    "## Essay\n",
    "{essay}\n",
    "\"\"\",\n",
    "\n",
    "    \"2\": \"\"\"\n",
    "논문의 본문과 참고문헌 목록을 정리해야 합니다.  \n",
    "논문에서 특정 참고문헌이 인용되었을 경우,\n",
    "해당 참고문헌의 **인용 횟수(`\"Counter\"`)**와 **인용 문장(`\"Context\"`)**을 JSON으로 출력하세요.  \n",
    "**본문에서 한 번도 인용되지 않은 참고문헌은 출력하지 않습니다.**\n",
    "\n",
    "## 조건\n",
    "- 인용 표시: 참고문헌이 본문에서 **[숫자]** (`[7]`, `[19]` 등) 형식으로 등장하는 경우만 포함합니다.\n",
    "- 동일한 참고문헌이 여러 번 인용되었을 경우, `\"Context\"` 배열에 각 인용 문장을 저장합니다.\n",
    "- `\"Context\"`의 각 문장은 **300자 이내**로 제한해야 합니다.\n",
    "\n",
    "## 출력 예시\n",
    "```json\n",
    "{{\n",
    "    \"7\": {{\n",
    "        \"Title\": \"참고문헌 제목1\",\n",
    "        \"Counter\": 3,\n",
    "        \"Context\": [\"첫 번째 인용 문장\", \"두 번째 인용 문장\", \"세 번째 인용 문장\"]\n",
    "    }},\n",
    "    \"19\": {{\n",
    "        \"Title\": \"참고문헌 제목2\",\n",
    "        \"Counter\": 1,\n",
    "        \"Context\": [\"인용된 문장\"]\n",
    "    }}\n",
    "}}\n",
    "```\n",
    "\n",
    "## References\n",
    "{references}\n",
    "\n",
    "## Essay\n",
    "{essay}\n",
    "\"\"\",\n",
    "\n",
    "    \"3\": \"\"\"\n",
    "논문의 본문과 참고문헌 목록이 주어졌습니다.  \n",
    "논문에서 참고문헌이 인용되었다면,\n",
    "해당 참고문헌의 인용 횟수를 `\"Counter\"`에 기록하고,  \n",
    "인용된 문장을 300자 이내로 정리하여 `\"Context\"` 배열에 저장하세요.  \n",
    "**인용되지 않은 참고문헌은 출력하지 않습니다.**\n",
    "\n",
    "## 조건\n",
    "- 인용 표시: 참고문헌이 본문에서 **[숫자]** (`[6]`, `[22]` 등) 형식으로 등장한 경우만 포함합니다.\n",
    "- 동일한 참고문헌이 여러 번 인용된 경우 `\"Context\"` 배열에 모든 인용 문장을 기록합니다.\n",
    "- `\"Context\"`의 개별 항목은 **최대 300자 이하**로 제한합니다.\n",
    "\n",
    "## 출력 예시\n",
    "```json\n",
    "{{\n",
    "    \"6\": {{\n",
    "        \"Title\": \"참고문헌 제목1\",\n",
    "        \"Counter\": 4,\n",
    "        \"Context\": [\"첫 번째 인용 문장\", \"두 번째 인용 문장\", \"세 번째 인용 문장\", \"네 번째 인용 문장\"]\n",
    "    }},\n",
    "    \"22\": {{\n",
    "        \"Title\": \"참고문헌 제목2\",\n",
    "        \"Counter\": 2,\n",
    "        \"Context\": [\"첫 번째 인용 문장\", \"두 번째 인용 문장\"]\n",
    "    }}\n",
    "}}\n",
    "```\n",
    "\n",
    "## References\n",
    "{references}\n",
    "\n",
    "## Essay\n",
    "{essay}\n",
    "\"\"\",\n",
    "\n",
    "    \"4\": \"\"\"\n",
    "논문 본문에서 참고문헌이 인용된 경우, 해당 참고문헌의 **인용 횟수**와 **인용 문장**을 정리하여 JSON 형식으로 출력하세요.  \n",
    "**인용되지 않은 참고문헌은 제외합니다.**\n",
    "\n",
    "## 조건\n",
    "- 인용표시: 논문 본문에서 참고문헌이 **[숫자]** (`[4]`, `[18]` 등) 형식으로 인용되었을 경우만 수집합니다.\n",
    "- 동일한 참고문헌이 여러 번 인용된 경우 `\"Context\"` 배열에 해당 문장들을 포함합니다.\n",
    "- `\"Context\"`의 개별 문장은 **300자 이하**로 유지해야 합니다.\n",
    "\n",
    "## 출력 예시\n",
    "```json\n",
    "{{\n",
    "    \"4\": {{\n",
    "        \"Title\": \"참고문헌 제목1\",\n",
    "        \"Counter\": 5,\n",
    "        \"Context\": [\"첫 번째 인용 문장\", \"두 번째 인용 문장\", \"세 번째 인용 문장\", \"네 번째 인용 문장\", \"다섯 번째 인용 문장\"]\n",
    "    }},\n",
    "    \"18\": {{\n",
    "        \"Title\": \"참고문헌 제목2\",\n",
    "        \"Counter\": 2,\n",
    "        \"Context\": [\"첫 번째 인용 문장\", \"두 번째 인용 문장\"]\n",
    "    }}\n",
    "}}\n",
    "```\n",
    "\n",
    "## References\n",
    "{references}\n",
    "\n",
    "## Essay\n",
    "{essay}\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인용횟수를 카운팅하여 타겟 논문과 참고 논문 사이의 형식적 관련성을 평가합니다. \n",
    "n = 5\n",
    "result_ = []\n",
    "for index in range(n):\n",
    "    result = []\n",
    "    for key in reference_count_keys:\n",
    "        for essay in output[key]:\n",
    "            user_message = user_message_template_dict[str(index)].format(references=reference_dict, essay=essay)\n",
    "            response = message_to_openai(user_message)\n",
    "            try:\n",
    "                text = response.choices[0].message.content\n",
    "                text = re.sub(\"```json\",\"\",text)\n",
    "                text = re.sub(\"```\",\"\",text)\n",
    "                text_data = json.loads(text)\n",
    "                result.append(text_data)\n",
    "            except: \n",
    "                text_data = None\n",
    "            # items['References'] = text_data\n",
    "    result_.append(result)\n",
    "\n",
    "    for data in result:\n",
    "        for key, value_dict in data.items():\n",
    "            output[\"References\"][key]['Counter'] += value_dict['Counter']\n",
    "            output[\"References\"][key]['Context'].extend(value_dict['Context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_950/372705134.py:13: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 논문 다운로드 완료\n",
      "2 번째 논문 다운로드 완료\n",
      "3 번째 논문 다운로드 완료\n",
      "4 번째 논문 다운로드 완료\n",
      "5 번째 논문 다운로드 완료\n",
      "6 번째 논문 다운로드 완료\n",
      "7 번째 논문 다운로드 완료\n",
      "8 번째 논문 다운로드 완료\n",
      "9 번째 논문 다운로드 완료\n",
      "10 번째 논문 다운로드 완료\n",
      "11 번째 논문 다운로드 완료\n",
      "12 번째 논문 다운로드 완료\n",
      "13 번째 논문 다운로드 완료\n",
      "14 번째 논문 다운로드 완료\n",
      "15 번째 논문 다운로드 완료\n",
      "16 번째 논문 다운로드 실패\n",
      "    Measuring causal effects of data statistics on language model’s ’factual’ predictions\n",
      "17 번째 논문 다운로드 완료\n",
      "18 번째 논문 다운로드 완료\n",
      "19 번째 논문 다운로드 완료\n",
      "20 번째 논문 다운로드 완료\n",
      "21 번째 논문 다운로드 실패\n",
      "    Olmo: Accelerating the science of language models\n",
      "22 번째 논문 다운로드 실패\n",
      "    Investigating learning dynamics of bert fine-tuning\n",
      "23 번째 논문 다운로드 실패\n",
      "    Training compute-optimal large language models\n",
      "24 번째 논문 다운로드 완료\n",
      "25 번째 논문 다운로드 완료\n",
      "26 번째 논문 다운로드 완료\n",
      "27 번째 논문 다운로드 완료\n",
      "28 번째 논문 다운로드 완료\n",
      "29 번째 논문 다운로드 완료\n",
      "30 번째 논문 다운로드 실패\n",
      "    Starcoder: may the source be with you!\n",
      "31 번째 논문 다운로드 완료\n",
      "32 번째 논문 다운로드 완료\n",
      "33 번째 논문 다운로드 완료\n",
      "34 번째 논문 다운로드 완료\n",
      "35 번째 논문 다운로드 완료\n",
      "36 번째 논문 다운로드 완료\n",
      "37 번째 논문 다운로드 완료\n",
      "38 번째 논문 다운로드 완료\n",
      "39 번째 논문 다운로드 완료\n",
      "40 번째 논문 다운로드 완료\n",
      "41 번째 논문 다운로드 완료\n",
      "42 번째 논문 다운로드 실패\n",
      "    Noise-robust de-duplication at scale\n",
      "43 번째 논문 다운로드 완료\n",
      "44 번째 논문 다운로드 완료\n",
      "45 번째 논문 예외 발생:  Page of results was unexpectedly empty (https://export.arxiv.org/api/query?search_query=Emergent+structures+and+training+dynamics+in+large+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=9&max_results=100)\n",
      "45 번째 논문 다운로드 실패\n",
      "    Emergent structures and training dynamics in large language models\n",
      "46 번째 논문 다운로드 완료\n",
      "47 번째 논문 다운로드 완료\n",
      "48 번째 논문 예외 발생:  Page of results was unexpectedly empty (https://export.arxiv.org/api/query?search_query=Llama%3A+Open+and+efficient+foundation+language+models&id_list=&sortBy=relevance&sortOrder=descending&start=100&max_results=100)\n",
      "48 번째 논문 다운로드 완료\n",
      "49 번째 논문 다운로드 완료\n",
      "50 번째 논문 다운로드 완료\n",
      "51 번째 논문 다운로드 완료\n",
      "52 번째 논문 다운로드 완료\n",
      "53 번째 논문 다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_arxiv_paper(title, max_results=30):\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=title,\n",
    "        max_results=max_results, \n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    for result in search.results():\n",
    "        if title[10:-10].lower().replace(\" \", \"\") in result.title.lower().replace(\" \", \"\"):\n",
    "            return ( {\n",
    "                \"title\": result.title,\n",
    "                \"abstract\": result.summary,\n",
    "                \"pdf_url\": result.pdf_url\n",
    "            })\n",
    "        \n",
    "    return None \n",
    "\n",
    "def download_arxiv_pdf(pdf_url, save_path):\n",
    "    response = requests.get(pdf_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                file.write(chunk)\n",
    "    \n",
    "for index in range(len(output['References'])):\n",
    "    title = output['References'][str(index+1)]['Title']\n",
    "    try :\n",
    "        paper_info = fetch_arxiv_paper(title)\n",
    "        if paper_info is None:\n",
    "            paper_info = fetch_arxiv_paper(title, 150)\n",
    "    except Exception as e:\n",
    "        print(index+1,\"번째 논문 예외 발생: \", e)\n",
    "        try :\n",
    "            paper_info = fetch_arxiv_paper(title, None)\n",
    "        except:\n",
    "            paper_info = None\n",
    "\n",
    "    if paper_info is not None:\n",
    "        pdf_url = paper_info['pdf_url']\n",
    "        abstract = paper_info['abstract']\n",
    "        output['References'][str(index+1)]['abstract'] = abstract\n",
    "        output['References'][str(index+1)]['pdf_url'] = pdf_url\n",
    "        save_path = Path(\"references\") / (str(index+1)+ \"-\" + paper_info['title'][:15]+\".pdf\")\n",
    "        download_arxiv_pdf(pdf_url, save_path)\n",
    "        print(index+1,\"번째 논문 다운로드 완료\")\n",
    "    \n",
    "    else:\n",
    "        pdf_url = None\n",
    "        abstract = None\n",
    "        output['References'][str(index+1)]['abstract'] = abstract\n",
    "        output['References'][str(index+1)]['pdf_url'] = pdf_url\n",
    "        print(index+1,\"번째 논문 다운로드 실패\")\n",
    "        print(f\"    {output['References'][str(index+1)]['Title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운이 안받아진 논문은 제외합니다. \n",
    "# 해당 셀 위에 수동으로 넣으면 이를 반영시킬 수 있습니다.\n",
    "filtered_reference_dict = { key: value for key, value in output['References'].items() if value['pdf_url'] is not None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 다운로드 실패된 논문은 직접 가져오고, abstract도 직접 작성해서 넣어야 합니다.\n",
    "# output['References']['16']['abstract'] = \"Large amounts of training data are one of the major reasons for the high performance of state-of-the-art NLP models. But what exactly in the training data causes a model to make a certain prediction? We seek to answer this question by providing a language for describing how training data influences predictions, through a causal framework. Importantly, our framework bypasses the need to retrain expensive models and allows us to estimate causal effects based on observational data alone. Addressing the problem of extracting factual knowledge from pretrained language models (PLMs), we focus on simple data statistics such as co-occurrence counts and show that these statistics do influence the predictions of PLMs, suggesting that such models rely on shallow heuristics. Our causal framework and our results demonstrate the importance of studying datasets and the benefits of causality for understanding NLP models.\"\n",
    "# output['References']['21']['abstract'] = \"Language models (LMs) have become ubiquitous in both NLP research and in commercial product offerings. As their commercial importance has surged, the most powerful models have become closed off, gated behind proprietary interfaces, with important details of their training data, architectures, and development undisclosed. Given the importance of these details in scientifically studying these models, including their biases and potential risks, we believe it is essential for the research community to have access to powerful, truly open LMs. To this end, we have built OLMo, a competitive, truly Open Language Model, to enable the scientific study of language models. Unlike most prior efforts that have only released model weights and inference code, we release OLMo alongside open training data and training and evaluation code. We hope this release will empower the open research community and inspire a new wave of innovation.\"\n",
    "# output['References']['22']['abstract'] = \"\"\"\n",
    "# The recently introduced pre-trained language\n",
    "# model BERT advances the state-of-the-art on\n",
    "# many NLP tasks through the fine-tuning approach, but few studies investigate how the\n",
    "# fine-tuning process improves the model performance on downstream tasks. In this paper, we inspect the learning dynamics of BERT\n",
    "# fine-tuning with two indicators. We use JS\n",
    "# divergence to detect the change of the attention mode and use SVCCA distance to examine the change to the feature extraction mode\n",
    "# during BERT fine-tuning. We conclude that\n",
    "# BERT fine-tuning mainly changes the attention mode of the last layers and modifies the\n",
    "# feature extraction mode of the intermediate\n",
    "# and last layers. Moreover, we analyze the consistency of BERT fine-tuning between different random seeds and different datasets. In\n",
    "# summary, we provide a distinctive understanding of the learning dynamics of BERT finetuning, which sheds some light on improving\n",
    "# the fine-tuning results.\"\"\"\n",
    "# output['References']['23']['abstract'] = \"We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4× more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher.\"\n",
    "# output['References']['30']['abstract'] = \"The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.\"\n",
    "# output['References']['44']['abstract'] = \"State-of-the-art pre-trained language models have been shown to memorise facts and perform well with limited amounts of training data. To gain a better understanding of how these models learn, we study their generalisation and memorisation capabilities in noisy and low-resource scenarios. We find that the training of these models is almost unaffected by label noise and that it is possible to reach near-optimal results even on extremely noisy datasets. However, our experiments also show that they mainly learn from high-frequency patterns and largely fail when tested on low-resource tasks such as few-shot learning and rare entity recognition. To mitigate such limitations, we propose an extension based on prototypical networks that improves performance in low-resource named entity recognition tasks.\"\n",
    "# output['References']['45']['abstract'] = \"\"\"\n",
    "# Large language models have achieved success\n",
    "# on a number of downstream tasks, particularly\n",
    "# in a few and zero-shot manner. As a consequence, researchers have been investigating\n",
    "# both the kind of information these networks\n",
    "# learn and how such information can be encoded\n",
    "# in the parameters of the model. We survey\n",
    "# the literature on changes in the network during\n",
    "# training, drawing from work outside of NLP\n",
    "# when necessary, and on learned representations\n",
    "# of linguistic features in large language models.\n",
    "# We note in particular the lack of sufficient research on the emergence of functional units –\n",
    "# subsections of the network where related functions are grouped or organized – within large\n",
    "# language models, and motivate future work that\n",
    "# grounds the study of language models in an\n",
    "# analysis of their changing internal structure during training time.\n",
    "# \"\"\"\n",
    "# output['References']['48']['abstract'] = \"\"\"\n",
    "# We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research\n",
    "# \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_template = \"\"\"\n",
    "다음 문장들을 분석하여 의미적으로 유사한 문장은 모두 제거하고, 서로 독립적인 문장만 남겨주세요.\n",
    "\n",
    "### 입력 문장 목록:\n",
    "{text_list}\n",
    "\n",
    "### 출력 형식:\n",
    "- 중복되거나 유사한 문장을 제거한 후, 의미적으로 독립적인 문장만 번호와 함께 남겨주세요.\n",
    "- 출력 결과는 원래 문장의 의미를 유지하면서 중복을 피하도록 정제해주세요.\n",
    "\n",
    "### 결과 예시 :\n",
    "1. [27] reported that the performance of LLMs adheres to a scaling law, correlating positively with both the model size and the size of the pretraining corpus.\n",
    "2. In Eq.1, the definition of the local acquisition maxima is also dependent on the injected knowledge k and the window size tw, but we write tLAM(q, i) for brevity.\n",
    "3. While our finding that effectivity remains unchanged for different stages of pretraining may seem contradictory to the widely known observation that the amount of pretraining data is a critical factor in the performance of LLMs [23, 27], we suggest a plausible hypothesis based on further observations in §4.3.\n",
    "\n",
    "위와 같은 방식으로 유사한 문장을 제거하고 정제된 결과를 반환해주세요.\n",
    "\n",
    "\"\"\"\n",
    "ratio = 0.2\n",
    "nums = int(round(len(output['References']) * ratio, 0))\n",
    "related_reference = dict(sorted(filtered_reference_dict.items(), key=lambda x:x[1]['Counter'], reverse=True)[:nums])\n",
    "\n",
    "for index in related_reference.keys():\n",
    "    query_list = related_reference[index]['Context']\n",
    "    user_message = user_message_template.format(text_list=query_list)\n",
    "    response = message_to_openai(user_message)\n",
    "    related_reference[index]['Questions'] = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "인용 논문과의 관련 지점 정리...: 100%|██████████| 11/11 [04:45<00:00, 25.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "user_message_template = \"\"\"\n",
    "다음 문서를 보고 질문은 한국어로 번역하여 출력해주세요.\n",
    "질문에 대한 답변 및 관련 지식을 한국어로 요약하고, 답변의 근거가 되는 부분을 논문에서 그대로 발췌해 주세요.\n",
    "그리고 모든 질문에 대한 답변을 500자 내외의 한 단락으로 정리해주세요.\n",
    "### 인용 논문 제목 (Title): {title}\n",
    "### 질문 목록 (Questions): {questions}\n",
    "### 문서 (Document): {essay}\n",
    "### 답변 예시 (Example Answer):\n",
    "인용 논문 제목 (Title): <<논문 제목>>\n",
    "1. **질문 :** <<질문1-한국어로 번역된 질문>>\n",
    "   - **답변 :** <<질문1에 대한 한국어 답변이나 관련 지식 한 단락(300자 내외)>>\n",
    "   - **근거 :** <<인용 논문에서 해당 답변을 뒷받침하는 문장>>\n",
    "\n",
    "2. **질문 :** <<질문2-한국어로 번역된 질문>>\n",
    "   - **답변 :** <<질문2에 대한 한국어 답변이나 관련 지식 한 단락(300자 내외)>>\n",
    "   - **근거 :** <<인용 논문에서 해당 답변을 뒷받침하는 문장>>\n",
    "...\n",
    "\n",
    "답변 요약 \n",
    ": <<전체 답변에 대한 요약 한 단락(500자 내외)>>\n",
    "### 답변 요약 (Summary of Answers)\n",
    "\"\"\"\n",
    "\n",
    "user_message_template_2 = \"\"\"\n",
    "다음은 논문과 해당 논문의 참고문헌에 관한 내용입니다.\n",
    "해당 논문이 인용 논문에서의 주요 질의 응답에 대하여 어떻게 연구를 발전시켰는지 한 단락으로 서술해주세요.\n",
    "\n",
    "### 해당 논문 제목 (Title): {title}\n",
    "### 해당 논문 내용 (Essay): {essay}\n",
    "### 참고 문헌에 대한 주요 질의 응답(QnA): {qna}\n",
    "\n",
    "### 답변 예시 (Example Answer):\n",
    "인용 논문 제목 (Title): <<논문 제목>>\n",
    "<<참고 문헌에 대한 주요 질의 응답에 대하여 어떻게 논문이 연구를 발전시켰는지 300자 내외로 서술>>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "data_dir = Path('references')\n",
    "threshold = 25\n",
    "main_essay = \"\\n\\n\".join([output[key] for key in ['Title','Authors','Abstract']])\n",
    "for key in ['Introduction', 'Related Work', 'Experimental Setup', 'Results', 'Discussion and Conclusions']:\n",
    "    for doc in output[key]:\n",
    "        main_essay += (doc.page_content + \"\\n\\n\")\n",
    "\n",
    "for index in tqdm(related_reference.keys(), desc=\"인용 논문과의 관련 지점 정리...\"):\n",
    "   title = related_reference[index]['Title']\n",
    "   questions = related_reference[index]['Questions']\n",
    "   \n",
    "   # 논문 파일 찾기\n",
    "   for path in data_dir.rglob(\"*.pdf\"):\n",
    "      if path.name.split(\"-\")[0] == index:\n",
    "         break\n",
    "   \n",
    "   # PDF 로드\n",
    "   loader = UnstructuredPDFLoader(path)\n",
    "   documents = loader.load()\n",
    "   essay = documents[0].page_content\n",
    "   essay = \"\\n\".join([text for text in essay.split(\"\\n\") if len(text) >= threshold])\n",
    "   user_message = user_message_template.format(essay = essay, questions=questions, title=title)\n",
    "   response = message_to_openai(user_message)\n",
    "   summary = response.choices[0].message.content\n",
    "   related_reference[index]['Summary'] = summary\n",
    "   \n",
    "   user_message_2 = user_message_template_2.format(title=output['Title'], essay=main_essay, qna = summary)\n",
    "   response = message_to_openai(user_message_2)\n",
    "   summary_qna = response.choices[0].message.content\n",
    "   related_reference[index]['Summary_QnA'] = summary_qna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인용 논문 제목 (Title): Deduplicating training data makes language models better\n",
      "\n",
      "1. **질문 :** LLMs는 훈련 데이터의 상당 부분을 기억한다. 모델의 크기가 커질수록 훈련 데이터를 기억하는 경향이 증가하며, 이는 지식의 일반화 능력에 해를 끼치지 않는다.\n",
      "   - **답변 :** 대형 언어 모델(LLM)은 훈련 데이터의 상당 부분을 기억하는 경향이 있으며, 모델의 크기가 커질수록 이러한 경향이 더욱 두드러진다. 그러나 이 기억은 모델의 일반화 능력에 부정적인 영향을 미치지 않는다. 연구에 따르면, LLM은 훈련 데이터의 1% 이상을 그대로 출력할 수 있으며, 이는 모델의 크기와 관계없이 발생한다.\n",
      "   - **근거 :** \"Over 1% of tokens emitted unprompted from a model trained on standard datasets (e.g., C4) are part of a memorized sequence.\"\n",
      "\n",
      "2. **질문 :** 우리는 LLM이 비인기 지식을 습득하는 데 어려움을 겪는다고 가정한다. 이는 충분한 노출이 필요하기 때문이다. 우리의 발견은 사전 훈련 코퍼스를 중복 제거하면 LLM 성능이 향상된다는 것을 시사한다.\n",
      "   - **답변 :** LLM은 비인기 지식을 습득하는 데 어려움을 겪으며, 이는 충분한 노출이 필요하기 때문이다. 중복 제거를 통해 훈련 데이터의 품질을 높이면 LLM의 성능이 향상된다. 중복된 시퀀스에 더 높은 확률을 부여하는 것을 방지하고, 습득한 일반화를 더 오래 유지할 수 있도록 돕는다.\n",
      "   - **근거 :** \"Our findings suggest that deduplicating the pretraining corpus improves LLM performance by preventing the model from assigning a higher probability to duplicated sequences.\"\n",
      "\n",
      "3. **질문 :** 우리의 발견은 사전 훈련 코퍼스를 중복 제거하면 LLM 성능이 향상된다는 것을 시사한다.\n",
      "   - **답변 :** 사전 훈련 코퍼스를 중복 제거하면 LLM의 성능이 향상된다는 연구 결과가 있다. 중복 제거는 모델이 중복된 시퀀스에 높은 확률을 부여하는 것을 방지하고, 습득한 일반화를 더 오래 유지할 수 있도록 돕는다. 이는 모델의 출력에서 기억된 텍스트의 빈도를 줄이는 데 기여한다.\n",
      "   - **근거 :** \"Deduplication allows us to train models that emit memorized text ten times less frequently.\"\n",
      "\n",
      "답변 요약 \n",
      ": 대형 언어 모델(LLM)은 훈련 데이터의 상당 부분을 기억하는 경향이 있으며, 모델의 크기가 커질수록 이러한 경향이 더욱 두드러진다. 그러나 이 기억은 모델의 일반화 능력에 해를 끼치지 않는다. LLM은 비인기 지식을 습득하는 데 어려움을 겪으며, 이는 충분한 노출이 필요하기 때문이다. 중복 제거를 통해 훈련 데이터의 품질을 높이면 LLM의 성능이 향상된다. 중복된 시퀀스에 더 높은 확률을 부여하는 것을 방지하고, 습득한 일반화를 더 오래 유지할 수 있도록 돕는다. 이러한 연구 결과는 LLM의 훈련 데이터 중복 제거가 모델의 성능을 개선하는 데 중요한 역할을 한다는 것을 시사한다.\n",
      "\n",
      "인용 논문 제목 (Title): Deduplicating training data makes language models better\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)의 사실 지식 습득 메커니즘을 심층적으로 분석하며, 중복 제거가 LLM 성능 향상에 미치는 영향을 강조한다. LLM이 비인기 지식을 습득하는 데 어려움을 겪는 이유를 충분한 노출의 필요성으로 설명하고, 중복 제거가 모델이 중복된 시퀀스에 높은 확률을 부여하는 것을 방지하여 습득한 일반화를 더 오래 유지하도록 돕는다는 점을 제시한다. 이러한 발견은 LLM의 훈련 데이터 중복 제거가 모델의 성능을 개선하는 데 중요한 역할을 한다는 기존 연구를 뒷받침하며, LLM의 사실 지식 습득 동역학에 대한 이해를 심화시킨다.\n",
      "####\n",
      "인용 논문 제목 (Title): Memorization without overfitting: Analyzing the training dynamics of large language models\n",
      "\n",
      "1. **질문 :** [46]은 다양한 사전 훈련 조건에서 LLM의 암기 및 망각 행동에 대한 광범위한 분석을 수행했습니다.\n",
      "   - **답변 :** [46]의 연구는 대형 언어 모델(LLM)의 암기 및 망각 행동을 다양한 사전 훈련 조건에서 분석하였으며, 이 연구는 모델의 크기와 훈련 과정에서의 암기 동역학을 이해하는 데 기여했습니다. \n",
      "   - **근거 :** \"We empirically study exact memorization in causal and masked language modeling, across model sizes and throughout the training process.\"\n",
      "\n",
      "2. **질문 :** 훈련 단계와 습득한 사실 지식의 망각은 거듭제곱 법칙 관계를 가지고 있습니다.\n",
      "   - **답변 :** 훈련 단계가 증가함에 따라 모델이 기억하는 데이터의 비율이 감소하는 경향이 있으며, 이는 거듭제곱 법칙에 따라 설명될 수 있습니다. 즉, 훈련 단계가 많아질수록 망각이 더 빠르게 진행됩니다.\n",
      "   - **근거 :** \"We find that larger language models memorize training data faster.\"\n",
      "\n",
      "3. **질문 :** 망각의 기하급수적 경향은 LLM 훈련의 다양한 측면에서 보고되었습니다.\n",
      "   - **답변 :** LLM 훈련에서 망각의 기하급수적 경향은 사전 훈련에서의 암기 및 지속적인 학습에서의 작업 성능 등 여러 측면에서 관찰되었습니다. 이는 모델이 훈련 중에 기억한 정보를 잃는 경향을 나타냅니다.\n",
      "   - **근거 :** \"We show that forgetting curves have lower bounds — we coin this as the forgetting baseline.\"\n",
      "\n",
      "답변 요약 \n",
      ": 이 논문은 대형 언어 모델의 훈련 동역학을 분석하며, 특히 암기와 망각의 관계를 탐구합니다. [46]의 연구는 다양한 사전 훈련 조건에서 LLM의 암기 및 망각 행동을 분석하였고, 훈련 단계가 증가함에 따라 모델이 기억하는 데이터의 비율이 감소하는 경향이 있음을 보여줍니다. 또한, 망각의 기하급수적 경향은 LLM 훈련의 여러 측면에서 관찰되며, 이는 모델이 훈련 중에 기억한 정보를 잃는 경향을 나타냅니다. 이러한 연구 결과는 대형 언어 모델의 훈련 및 일반화 능력을 이해하는 데 중요한 통찰을 제공합니다.\n",
      "\n",
      "인용 논문 제목 (Title): Memorization without overfitting: Analyzing the training dynamics of large language models\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)의 훈련 동역학을 심층적으로 분석하며, 특히 암기와 망각의 관계를 탐구합니다. [46]의 연구를 바탕으로, 훈련 단계가 증가함에 따라 모델이 기억하는 데이터의 비율이 감소하는 경향을 확인하였고, 이는 거듭제곱 법칙에 의해 설명됩니다. 또한, 망각의 기하급수적 경향이 LLM 훈련의 여러 측면에서 관찰되며, 이는 모델이 훈련 중에 기억한 정보를 잃는 경향을 나타냅니다. 이러한 통찰은 LLM의 사실 지식 습득 및 일반화 능력을 이해하는 데 기여하며, 훈련 조건의 최적화를 위한 기초 자료를 제공합니다.\n",
      "####\n",
      "인용 논문 제목 (Title): Physics of language models: Part 3.1, knowledge storage and extraction\n",
      "\n",
      "1. **질문 :** 모델이 지식이 주입된 배치로 업데이트된 후, 프로브에서 측정된 모델의 로그 확률은 즉각적이고 뚜렷한 증가를 보인다. \n",
      "   - **답변 :** 모델이 지식이 주입된 배치로 업데이트되면, 로그 확률이 즉각적으로 증가하는 경향이 있다. 이는 모델이 새로운 지식을 효과적으로 저장하고 추출할 수 있음을 나타낸다.\n",
      "   - **근거 :** \"the model’s log probability measured on the probes shows an immediate and distinctive increase, after the model is updated with the batch containing the injected knowledge.\"\n",
      "\n",
      "2. **질문 :** [4]는 지식이 신뢰성 있게 추출되기 위해서는 다양한 형식으로 제공되어야 한다고 입증했다.\n",
      "   - **답변 :** 다양한 형식으로 제공된 지식은 모델이 이를 신뢰성 있게 추출하는 데 필수적이다. 이는 지식의 다양성이 모델의 학습에 긍정적인 영향을 미친다는 것을 의미한다.\n",
      "   - **근거 :** \"knowledge should be presented in a diverse format during pretraining to be reliably extracted.\"\n",
      "\n",
      "3. **질문 :** R(p, t) = 0은 tpre에서 주입된 지식을 포함한 미니배치로 모델을 업데이트한 후 사실적 지식의 로그 확률 개선이 완전히 사라졌음을 나타낸다.\n",
      "   - **답변 :** R(p, t) = 0은 주입된 지식이 모델에 효과적으로 저장되지 않았음을 나타내며, 이는 지식 추출의 실패를 의미한다.\n",
      "   - **근거 :** \"R(p, t) = 0 indicates that the improvement in the log probability of factual knowledge... is completely lost.\"\n",
      "\n",
      "4. **질문 :** 우리는 OLMo를 실험에 사용한다. 왜냐하면 모델의 중간 체크포인트, 옵티마이저 상태 및 배치 시퀀스 데이터가 공개적으로 제공되기 때문이다.\n",
      "   - **답변 :** OLMo는 공개된 데이터와 체크포인트 덕분에 실험에 적합한 모델로 선택되었다.\n",
      "   - **근거 :** \"we use OLMo for the experiments since the intermediate checkpoints, optimizer states, and batch sequence data for pretraining the model are made publicly available.\"\n",
      "\n",
      "5. **질문 :** 우리가 조사하는 OLMo-7B의 모든 사전 훈련 단계에서 이러한 패턴이 일관되게 나타난다.\n",
      "   - **답변 :** OLMo-7B의 모든 사전 훈련 단계에서 지식 저장 및 추출의 패턴이 일관되게 나타나며, 이는 모델의 학습 과정에서 중요한 통찰을 제공한다.\n",
      "   - **근거 :** \"These patterns are consistent across all pretraining stages of OLMo-7B we investigate.\"\n",
      "\n",
      "6. **질문 :** OLMo-1B 초기 체크포인트의 독특한 행동은 모델이 사실적 지식을 안정적으로 습득하기 위해 특정 수의 토큰에 대한 사전 훈련이 필요할 수 있음을 시사한다.\n",
      "   - **답변 :** OLMo-1B의 초기 체크포인트에서 나타나는 행동은 모델이 사실적 지식을 안정적으로 습득하기 위해 충분한 양의 데이터에 노출되어야 함을 시사한다.\n",
      "   - **근거 :** \"the distinctive behavior of the OLMo-1B early checkpoint suggests that pretraining on a certain number of tokens may be required for the model to acquire factual knowledge stably.\"\n",
      "\n",
      "### 답변 요약 (Summary of Answers)\n",
      "이 논문에서는 대형 언어 모델(LLM)이 지식을 어떻게 저장하고 추출하는지를 다룬다. 모델이 지식이 주입된 배치로 업데이트되면 로그 확률이 즉각적으로 증가하며, 이는 모델이 새로운 지식을 효과적으로 저장하고 추출할 수 있음을 나타낸다. 다양한 형식으로 제공된 지식은 신뢰성 있는 추출을 위해 필수적이며, 주입된 지식이 효과적으로 저장되지 않으면 추출이 실패할 수 있다. OLMo 모델은 공개된 데이터 덕분에 실험에 적합하며, OLMo-7B의 모든 사전 훈련 단계에서 일관된 패턴이 나타난다. OLMo-1B의 초기 체크포인트는 모델이 사실적 지식을 안정적으로 습득하기 위해 충분한 양의 데이터에 노출되어야 함을 시사한다. 이러한 결과는 LLM의 지식 저장 및 추출 메커니즘을 이해하는 데 중요한 통찰을 제공한다.\n",
      "\n",
      "인용 논문 제목 (Title): Physics of language models: Part 3.1, knowledge storage and extraction\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)의 사실적 지식 습득 메커니즘을 심층적으로 분석하며, 지식이 주입된 배치로 업데이트된 후 모델의 로그 확률이 즉각적으로 증가하는 현상을 설명한다. 이는 모델이 새로운 지식을 효과적으로 저장하고 추출할 수 있음을 나타내며, 다양한 형식으로 제공된 지식이 신뢰성 있는 추출에 필수적임을 강조한다. 또한, OLMo 모델의 중간 체크포인트와 공개된 데이터의 활용은 실험의 신뢰성을 높이며, OLMo-1B 초기 체크포인트의 행동은 안정적인 지식 습득을 위한 충분한 데이터 노출의 필요성을 시사한다. 이러한 통찰은 LLM의 지식 저장 및 추출 메커니즘에 대한 이해를 심화시키고, 향후 연구 방향을 제시한다.\n",
      "####\n",
      "인용 논문 제목 (Title): Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?\n",
      "\n",
      "1. **질문 :** [44]와 [46]은 언어 모델 사전 훈련에서 기억화의 동역학에 초점을 맞췄다.\n",
      "   - **답변 :** 이 연구는 언어 모델의 사전 훈련 과정에서 기억화의 동역학을 분석하며, 모델이 새로운 지식을 통합하는 데 어려움을 겪는다는 점을 강조한다. 특히, 새로운 지식이 기존 지식과 일치하지 않을 경우, 모델이 이를 학습하는 속도가 느려진다는 결과를 보여준다.\n",
      "   - **근거 :** \"We demonstrate that large language models struggle to acquire new factual knowledge through fine-tuning, as fine-tuning examples that introduce new knowledge are learned significantly slower than those consistent with the model’s knowledge.\"\n",
      "\n",
      "2. **질문 :** 여러 연구들이 LLM의 훈련 동역학을 조사했으며, 특히 훈련 중 어떻게 발전하는지를 다루었다 [12, 18, 22, 32, 33, 45, 51].\n",
      "   - **답변 :** LLM의 훈련 동역학에 대한 연구는 모델이 훈련 중에 어떻게 지식을 습득하고 활용하는지를 분석하며, 특히 새로운 지식의 통합이 기존 지식의 활용에 미치는 영향을 탐구한다.\n",
      "   - **근거 :** \"We study how learning new factual knowledge through fine-tuning impacts the model’s tendency to hallucinate w.r.t. its pre-existing knowledge.\"\n",
      "\n",
      "3. **질문 :** 우리는 LLM이 비인기 지식을 습득하는 데 어려움을 겪는다고 가정한다. 이는 충분한 노출이 필요하기 때문이다.\n",
      "   - **답변 :** LLM은 비인기 지식을 습득하기 위해서는 사실적 지식에 대한 충분한 노출이 필요하며, 이 노출이 학습 가능성의 임계값보다 짧은 간격으로 이루어져야 한다.\n",
      "   - **근거 :** \"We hypothesize that LLMs struggle to acquire unpopular knowledge because they need sufficient exposure to factual knowledge with intervals shorter than the learnability threshold to increase the probability.\"\n",
      "\n",
      "4. **질문 :** 최근 [18]은 데이터 크기와 grokking 간의 관계를 탐구했다.\n",
      "   - **답변 :** 데이터 크기와 grokking 간의 관계를 탐구한 연구는 LLM이 훈련 중에 얼마나 효과적으로 지식을 습득하는지를 분석하며, 데이터의 양이 모델의 성능에 미치는 영향을 평가한다.\n",
      "   - **근거 :** \"We explore how LLMs acquire and retain factual knowledge in terms of memorization and generalization by examining the following factors.\"\n",
      "\n",
      "5. **질문 :** 우리는 LLM의 로그 확률 개선을 정량화하기 위해 효과성을 측정한다.\n",
      "   - **답변 :** LLM의 로그 확률 개선을 정량화하기 위해 효과성을 측정하는 방법을 사용하여, 새로운 지식이 모델의 성능에 미치는 영향을 분석한다.\n",
      "   - **근거 :** \"Next, we measure effectivity (Eq. 2) to quantify the improvement of the LLMs’ log probability after being trained with the injected knowledge.\"\n",
      "\n",
      "6. **질문 :** 이는 작은 배치 크기로 훈련된 모델이 짧은 학습 가능성 임계값을 가진다는 것을 의미한다.\n",
      "   - **답변 :** 작은 배치 크기로 훈련된 모델은 짧은 학습 가능성 임계값을 가지며, 이는 모델이 새로운 지식을 효과적으로 습득하는 데 어려움을 겪는다는 것을 나타낸다.\n",
      "   - **근거 :** \"This implies that the models trained with smaller batch sizes have shorter learnability threshold, the point such that an LLM cannot learn the knowledge presented with intervals longer than that threshold.\"\n",
      "\n",
      "7. **질문 :** 그러나 더 큰 모델의 경우, 지식 관찰 후 로그 확률의 즉각적인 개선량은 크게 증가하지 않는다.\n",
      "   - **답변 :** 더 큰 모델의 경우, 지식 관찰 후 로그 확률의 즉각적인 개선량은 증가하지만, 사전 훈련 진행 중에는 그 양이 크게 증가하지 않는다는 점이 관찰된다.\n",
      "   - **근거 :** \"However, while the amount of immediate improvement in log probability upon observation of the knowledge increases for larger models, the amount does not significantly increase throughout the progress of pretraining.\"\n",
      "\n",
      "답변 요약 \n",
      ": 이 연구는 LLM이 새로운 사실적 지식을 통합하는 과정에서 겪는 어려움과 그로 인해 발생하는 환각 현상에 대해 분석한다. LLM은 사전 훈련을 통해 기존 지식을 습득하지만, 새로운 지식을 효과적으로 학습하는 데는 시간이 걸리며, 이는 모델의 성능 저하로 이어질 수 있다. 특히, 비인기 지식의 습득은 충분한 노출이 필요하며, 이는 학습 가능성의 임계값과 관련이 있다. 연구 결과는 LLM의 훈련 동역학을 이해하는 데 중요한 통찰을 제공하며, 새로운 지식을 도입할 때의 위험성을 강조한다.\n",
      "\n",
      "인용 논문 제목 (Title): Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?\n",
      "\n",
      "해당 논문은 LLM이 새로운 사실적 지식을 통합하는 과정에서의 어려움과 그로 인해 발생하는 환각 현상을 분석하며, LLM의 훈련 동역학에 대한 이해를 심화시킨다. 특히, LLM이 비인기 지식을 습득하기 위해서는 충분한 노출이 필요하며, 이는 학습 가능성의 임계값과 밀접한 관련이 있음을 강조한다. 이러한 통찰은 LLM의 성능 저하를 방지하기 위한 전략을 제시하며, 새로운 지식을 도입할 때의 위험성을 경고한다. 이 연구는 LLM의 지식 습득 메커니즘을 보다 명확히 이해하는 데 기여하며, 향후 연구 방향을 제시한다.\n",
      "####\n",
      "인용 논문 제목 (Title): Scaling laws for neural language models\n",
      "\n",
      "1. **질문 :** [27]은 LLM의 성능이 모델 크기와 사전 훈련 코퍼스의 크기와 긍정적으로 상관관계가 있는 스케일링 법칙을 따른다고 보고했습니다.\n",
      "   - **답변 :** LLM의 성능은 모델의 크기와 데이터셋의 크기에 따라 증가하며, 이는 스케일링 법칙에 의해 설명됩니다. 즉, 모델의 크기와 데이터셋의 크기가 증가할수록 성능이 향상된다는 것입니다.\n",
      "   - **근거 :** \"Performance has a power-law relationship with each of the three scale factors N, D, C when not bottlenecked by the other two.\"\n",
      "\n",
      "2. **질문 :** 우리는 윈도우 크기를 tw = 50으로 설정합니다. 다음으로, 모델이 i번째로 지식을 제공받은 후 사실적 지식의 로그 확률에서 즉각적인 개선을 정량화하는 메트릭을 정의합니다.\n",
      "   - **답변 :** 윈도우 크기를 설정한 후, 모델이 특정 지식을 제공받은 후의 로그 확률 개선을 측정하기 위한 메트릭을 정의하여 모델의 성능을 평가합니다.\n",
      "   - **근거 :** \"Next, we define a metric to quantify the immediate improvement in the model’s log probability of factual knowledge after it is presented with the knowledge for the i-th time.\"\n",
      "\n",
      "3. **질문 :** 정의된 메트릭의 측정은 그림 1에 설명되어 있습니다. 효과성과 유지 가능성의 측정을 위해, 우리는 1.5의 계수를 사용하여 IQR 방법을 이용한 이상치 탐지를 적용합니다.\n",
      "   - **답변 :** 효과성과 유지 가능성을 측정하기 위해 IQR 방법을 사용하여 이상치를 탐지하고, 이를 통해 모델의 성능을 평가합니다.\n",
      "   - **근거 :** \"For the measurement of effectivity and retainability, we apply outlier detection using the IQR method with a factor of 1.5.\"\n",
      "\n",
      "4. **질문 :** 결과는 중복(상단), 패러프레이즈(중앙), 한 번(하단) 주입 시나리오에 대해 보여집니다.\n",
      "   - **답변 :** 다양한 주입 시나리오에 대한 결과를 통해 모델의 성능을 비교하고 분석합니다.\n",
      "   - **근거 :** \"Results are shown for duplicate (Top), paraphrase (Center), and once (Bottom) injection scenarios.\"\n",
      "\n",
      "5. **질문 :** 획득 깊이에 관계없이(기억, 의미 일반화 및 조합 일반화), 주입된 지식을 포함한 배치로 모델이 업데이트된 후 프로브에서 측정된 모델의 로그 확률은 즉각적이고 뚜렷한 증가를 보입니다.\n",
      "   - **답변 :** 모델이 주입된 지식으로 업데이트된 후, 로그 확률이 즉각적으로 증가하는 현상을 관찰할 수 있습니다.\n",
      "   - **근거 :** \"the model’s log probability measured on the probes shows an immediate and distinctive increase, after the model is updated with the batch containing the injected knowledge.\"\n",
      "\n",
      "6. **질문 :** 다음으로, 주입된 지식으로 훈련된 후 LLM의 로그 확률 개선을 정량화하기 위해 효과성을 측정합니다(Eq. 2).\n",
      "   - **답변 :** 주입된 지식으로 훈련된 후 LLM의 로그 확률 개선을 정량화하기 위해 효과성을 측정하는 방법을 사용합니다.\n",
      "   - **근거 :** \"Next, we measure effectivity (Eq. 2) to quantify the improvement of the LLMs’ log probability after being trained with the injected knowledge.\"\n",
      "\n",
      "7. **질문 :** 그림 5의 추정된 x-절편은 훈련을 통해 획득한 사실적 지식의 완전한 손실로 이어지는 추가 훈련 토큰의 수를 나타냅니다.\n",
      "   - **답변 :** 그림 5에서 x-절편을 통해 추가 훈련 토큰의 수를 추정하여 사실적 지식의 손실을 분석합니다.\n",
      "   - **근거 :** \"The estimated x-intercepts in Figure 5 represent the number of additional training tokens that would lead to the complete loss of the factual knowledge acquired by training.\"\n",
      "\n",
      "8. **질문 :** 훈련 단계와 획득한 사실적 지식의 망각 사이에는 힘 법칙 관계가 있습니다.\n",
      "   - **답변 :** 훈련 단계와 사실적 지식의 망각 사이에는 힘 법칙 관계가 존재하며, 이는 모델의 일반화 능력에 영향을 미칩니다.\n",
      "   - **근거 :** \"There is a power-law relationship between training steps and forgetting of acquired factual knowledge, in terms of both memorization and generalization.\"\n",
      "\n",
      "9. **질문 :** 우리는 LLM이 비인기 지식을 습득하는 데 어려움을 겪는다고 가정합니다.\n",
      "   - **답변 :** LLM은 비인기 지식을 습득하는 데 필요한 충분한 노출이 부족하여 어려움을 겪는다고 가정합니다.\n",
      "   - **근거 :** \"We hypothesize that LLMs struggle to acquire unpopular knowledge because they need sufficient exposure to factual knowledge with intervals shorter than the learnability threshold to increase the probability.\"\n",
      "\n",
      "### 답변 요약 (Summary of Answers)\n",
      "이 논문에서는 LLM의 성능이 모델 크기와 데이터셋 크기에 따라 증가하는 스케일링 법칙을 따르며, 이는 다양한 실험을 통해 입증되었습니다. 모델의 로그 확률 개선을 정량화하기 위한 메트릭을 정의하고, 효과성과 유지 가능성을 측정하기 위해 IQR 방법을 사용하여 이상치를 탐지합니다. 주입된 지식으로 업데이트된 후 모델의 성능이 즉각적으로 증가하는 현상을 관찰하였으며, 훈련 단계와 사실적 지식의 망각 사이에는 힘 법칙 관계가 존재합니다. 또한, LLM이 비인기 지식을 습득하는 데 어려움을 겪는 이유를 설명하며, 이러한 결과들은 LLM의 훈련 및 성능 최적화에 대한 중요한 통찰을 제공합니다.\n",
      "\n",
      "해당 논문은 LLM의 사실적 지식 습득 메커니즘을 심층적으로 분석하며, 인용 논문에서 제시된 스케일링 법칙과 관련된 성능 향상 원인을 탐구합니다. 특히, 모델 크기와 데이터셋 크기가 성능에 미치는 영향을 실험적으로 검증하고, 주입된 지식에 대한 즉각적인 로그 확률 개선을 관찰함으로써 LLM의 학습 동역학을 명확히 합니다. 또한, 훈련 단계와 망각 간의 힘 법칙 관계를 밝혀내어 LLM이 비인기 지식을 습득하는 데 어려움을 겪는 이유를 설명하며, 이러한 통찰은 LLM의 훈련 및 성능 최적화에 중요한 기여를 합니다.\n",
      "####\n",
      "인용 논문 제목 (Title): Language models are few-shot learners\n",
      "\n",
      "1. **질문 :** 최근 LLM에 대한 관심이 급증하고 있다 [9, 13, 21, 23, 49].\n",
      "   - **답변 :** 최근 몇 년간 대규모 언어 모델(LLM)에 대한 연구와 응용이 급증하고 있으며, 이는 자연어 처리(NLP) 분야에서의 혁신을 이끌고 있다. LLM은 다양한 작업에서 뛰어난 성능을 보여주며, 특히 적은 수의 예시로도 학습할 수 있는 능력으로 주목받고 있다. 이러한 모델들은 대량의 데이터로 사전 훈련되어, 다양한 언어적 과제를 수행할 수 있는 능력을 갖추고 있다.\n",
      "   - **근거 :** \"Language models are few-shot learners\"라는 제목에서 언급된 바와 같이, LLM은 적은 수의 예시로도 학습할 수 있는 능력을 가지고 있다.\n",
      "\n",
      "2. **질문 :** 최근의 사전 훈련 데이터는 철저히 중복 제거가 이루어졌다 [9, 28, 38, 43, 47, 48]. 데이터 중복 제거가 모델 성능을 향상시킬 수 있다는 것이 널리 관찰되고 있다 [1, 29, 42, 52].\n",
      "   - **답변 :** 최근의 사전 훈련 데이터는 중복 제거 과정을 통해 데이터의 질을 높이고, 모델의 성능을 향상시키는 데 기여하고 있다. 중복된 데이터가 많을 경우, 모델이 특정 패턴에 과적합될 위험이 있으며, 이는 일반화 성능을 저하시킬 수 있다. 따라서 중복 제거는 모델의 학습 효율성을 높이는 중요한 과정으로 인식되고 있다.\n",
      "   - **근거 :** \"it is widely observed that data deduplication can improve model performance\"라는 문장에서 데이터 중복 제거가 모델 성능 향상에 기여함을 명시하고 있다.\n",
      "\n",
      "3. **질문 :** 데이터 중복 제거가 모델 성능을 향상시킬 수 있다는 것이 널리 관찰되고 있다 [1, 29, 42, 52].\n",
      "   - **답변 :** 데이터 중복 제거는 모델이 학습하는 데 있어 중요한 역할을 하며, 이는 모델이 더 다양한 패턴을 학습할 수 있도록 돕는다. 중복된 데이터는 모델이 특정 예시에 과도하게 적응하게 만들 수 있으며, 이는 일반화 성능을 저하시킬 수 있다. 따라서 중복 제거는 모델의 성능을 높이는 데 필수적이다.\n",
      "   - **근거 :** \"data deduplication can improve model performance\"라는 문장에서 데이터 중복 제거의 중요성을 강조하고 있다.\n",
      "\n",
      "### 답변 요약 (Summary of Answers)\n",
      "최근 LLM에 대한 관심이 급증하고 있으며, 이는 자연어 처리 분야에서의 혁신을 이끌고 있다. LLM은 적은 수의 예시로도 학습할 수 있는 능력을 갖추고 있어 다양한 작업에서 뛰어난 성능을 보여준다. 최근의 사전 훈련 데이터는 중복 제거 과정을 통해 데이터의 질을 높이고, 모델의 성능을 향상시키는 데 기여하고 있다. 데이터 중복 제거는 모델이 학습하는 데 있어 중요한 역할을 하며, 이는 모델이 더 다양한 패턴을 학습할 수 있도록 돕는다. 중복된 데이터는 모델이 특정 예시에 과도하게 적응하게 만들 수 있으며, 이는 일반화 성능을 저하시킬 수 있다. 따라서 중복 제거는 모델의 성능을 높이는 데 필수적이다.\n",
      "\n",
      "해당 논문은 LLM의 사실적 지식 습득 메커니즘을 심층적으로 분석함으로써, 기존 연구에서 제기된 데이터 중복 제거의 중요성과 LLM의 성능 향상 간의 관계를 더욱 명확히 했다. 특히, 중복 제거가 모델의 일반화 성능을 높이는 데 기여한다는 점을 강조하며, 중복된 데이터가 과적합을 초래할 수 있음을 지적했다. 또한, LLM의 지식 습득 과정에서의 맥락적 요인과 훈련 조건이 지식의 기억 및 망각에 미치는 영향을 규명함으로써, LLM의 성능 향상에 대한 새로운 통찰을 제공하였다. 이러한 연구는 LLM의 훈련 및 활용에 있어 데이터 품질의 중요성을 재확인하는 데 기여한다.\n",
      "####\n",
      "인용 논문 제목 (Title): Are emergent abilities of large language models a mirage?\n",
      "\n",
      "1. **질문 :** LLM의 사실적 지식 습득을 상세히 분석하기 위해, 우리는 로그 확률을 검토하여 모델의 상태를 평가합니다. \n",
      "   - **답변 :** LLM의 사실적 지식 습득을 분석하기 위해 로그 확률을 통해 모델의 상태를 평가하는 방법은 모델이 지식을 어떻게 습득하는지를 세밀하게 이해하는 데 도움을 줍니다. 이 과정에서 로그 확률의 변화를 추적함으로써, 모델이 특정 지식을 얼마나 잘 인식하고 있는지를 파악할 수 있습니다.\n",
      "   - **근거 :** \"To conduct a detailed analysis of the LLMs’ acquisition of factual knowledge during pretraining, we evaluate the model’s state by examining log probabilities to obtain fine-grained information.\"\n",
      "\n",
      "2. **질문 :** 사실적 지식 습득의 추세를 정량적으로 측정하기 위해, 우리는 먼저 모델 업데이트의 지역적 효과가 완전히 반영되는 시점을 정의해야 합니다.\n",
      "   - **답변 :** 사실적 지식 습득의 추세를 정량적으로 측정하기 위해서는 모델 업데이트가 효과를 발휘하기 시작하는 시점을 정의하는 것이 중요합니다. 이 시점은 모델이 새로운 지식을 통합하고 이를 활용할 수 있는 능력이 발휘되는 순간을 나타냅니다.\n",
      "   - **근거 :** \"To quantitatively measure the trend of factual knowledge acquisition, we should first define the timestep where the local effect of updating the model using the injected knowledge completely pays off.\"\n",
      "\n",
      "3. **질문 :** 모델은 사전 훈련이 진행됨에 따라 지식의 로그 확률이 증가하고, 어느 시점에서 이 누적된 로그 확률이 모델의 디코딩 출력으로 지식을 생성할 만큼 충분히 높아질 것입니다.\n",
      "   - **답변 :** 모델은 사전 훈련 과정에서 지식에 대한 로그 확률을 누적하여, 특정 시점에 이 누적된 확률이 충분히 높아지면 해당 지식을 출력으로 생성할 수 있습니다. 이는 모델이 지식을 효과적으로 습득하고 활용할 수 있는 능력을 나타냅니다.\n",
      "   - **근거 :** \"The model will accumulate the increased log probability of the knowledge upon each encounter of the knowledge as the pretraining progresses, and at some point, the accumulated log probability of the knowledge will be high enough to generate the knowledge as the decoding output of the model.\"\n",
      "\n",
      "### 답변 요약 (Summary of Answers)\n",
      "이 논문에서는 대형 언어 모델(LLM)의 사실적 지식 습득 과정을 분석하기 위해 로그 확률을 평가하는 방법을 제시합니다. 이를 통해 모델이 지식을 어떻게 습득하는지를 세밀하게 이해할 수 있으며, 모델 업데이트의 효과가 나타나는 시점을 정의하는 것이 중요하다고 강조합니다. 또한, 모델은 사전 훈련 과정에서 지식에 대한 로그 확률을 누적하여, 특정 시점에 이 누적된 확률이 충분히 높아지면 해당 지식을 출력으로 생성할 수 있습니다. 이러한 분석은 LLM의 지식 습득 능력을 평가하는 데 중요한 기초 자료를 제공합니다.\n",
      "\n",
      "인용 논문 <<Are emergent abilities of large language models a mirage?>>에서 제기된 질의 응답을 바탕으로, 본 논문은 대형 언어 모델(LLM)의 사실적 지식 습득 과정을 보다 세밀하게 분석하는 방법론을 발전시켰습니다. 특히, 로그 확률을 통해 모델의 상태를 평가하고, 모델 업데이트의 효과가 나타나는 시점을 정의함으로써, LLM이 지식을 어떻게 습득하고 활용하는지를 명확히 밝혔습니다. 이러한 접근은 LLM의 지식 습득 능력을 정량적으로 측정할 수 있는 기초 자료를 제공하며, 모델이 사전 훈련 과정에서 지식의 로그 확률을 누적하여 출력으로 생성할 수 있는 메커니즘을 이해하는 데 기여합니다. 이를 통해 LLM의 학습 동역학에 대한 통찰을 제공하고, 향후 연구 방향을 제시합니다.\n",
      "####\n",
      "인용 논문 제목 (Title): To repeat or not to repeat: Insights from scaling llm under token-crisis\n",
      "\n",
      "1. **질문 :** 긴 꼬리 지식을 획득하지 못하는 이유는 무엇인가요?\n",
      "   - **답변 :** 긴 꼬리 지식의 획득 실패는 LLM이 비영어 데이터에서 성능이 떨어지는 것과 관련이 있습니다. LLM은 영어 데이터에 비해 비영어 데이터의 양이 적고, 이로 인해 다양한 언어와 문화적 맥락을 반영한 지식을 충분히 학습하지 못합니다. 이로 인해 LLM은 비영어 작업에서 성능이 저하됩니다.\n",
      "   - **근거 :** \"Despite PaLM’s impressive 540B parameters and training on 780B tokens, including 22% non-English data, it still lags behind models such as mT5 and ByT5 on non-English tasks like Multilingual QA.\"\n",
      "\n",
      "2. **질문 :** 중복된 텍스트를 제시할 때 모델이 사실적 지식을 일반화하는 데 더 빨리 잊어버리는 이유는 무엇인가요?\n",
      "   - **답변 :** 중복된 텍스트로 훈련된 모델은 과적합에 더 취약해지며, 이로 인해 일반화 능력이 저하됩니다. 특히, 데이터가 제한적일 때 모델은 반복된 정보를 빠르게 기억하지만, 이는 실제로는 더 많은 정보를 잊게 만드는 결과를 초래합니다.\n",
      "   - **근거 :** \"We observe that larger models are more susceptible to overfitting under token-crisis conditions.\"\n",
      "\n",
      "답변 요약 \n",
      ": 이 논문은 LLM이 긴 꼬리 지식을 획득하지 못하는 이유와 중복된 텍스트로 인해 사실적 지식을 잊어버리는 경향을 분석합니다. LLM은 비영어 데이터의 부족으로 인해 다양한 언어적 지식을 충분히 학습하지 못하며, 이는 비영어 작업에서 성능 저하로 이어집니다. 또한, 중복된 데이터로 훈련된 모델은 과적합에 취약해져 일반화 능력이 저하되며, 이는 모델이 반복된 정보를 빠르게 기억하지만, 동시에 더 많은 정보를 잊게 만드는 결과를 초래합니다. 이러한 결과는 LLM의 훈련 방식과 데이터의 질, 양에 따라 크게 영향을 받으며, 향후 LLM의 성능 향상을 위해서는 다양한 데이터와 훈련 전략이 필요함을 시사합니다.\n",
      "\n",
      "인용 논문 제목 (Title): To repeat or not to repeat: Insights from scaling llm under token-crisis\n",
      "\n",
      "해당 논문은 LLM이 긴 꼬리 지식을 획득하지 못하는 이유와 중복된 텍스트로 인해 사실적 지식을 잊어버리는 경향을 분석합니다. 이 논문은 LLM의 훈련 과정에서 비영어 데이터의 부족이 다양한 언어적 지식의 학습을 저해하며, 중복된 데이터로 훈련된 모델이 과적합에 취약해져 일반화 능력이 저하된다는 점을 강조합니다. 이러한 통찰은 LLM의 훈련 방식과 데이터의 질, 양이 성능에 미치는 영향을 이해하는 데 기여하며, 향후 LLM의 성능 향상을 위한 다양한 데이터와 훈련 전략의 필요성을 제시합니다.\n",
      "####\n",
      "인용 논문 제목 (Title): Language models as knowledge bases?\n",
      "\n",
      "1. **질문 :** 최근 연구들은 LLM이 사전 훈련 데이터에서 상당한 사실적 지식을 포착할 수 있는 능력을 보여주었다 [14, 36, 40].\n",
      "   - **답변 :** 최근 연구들은 대형 언어 모델(LLM)이 사전 훈련 데이터에서 상당한 사실적 지식을 포착할 수 있음을 보여주고 있습니다. LLM은 정보 검색 기술보다 지식 집약적인 작업에서 더 나은 성능을 발휘하며, 생성된 지식의 사실성은 다소 낮더라도 하위 작업에 미치는 영향이 크지 않다는 결과를 보였습니다. \n",
      "   - **근거 :** \"LLM-generated knowledge surpasses retrieved knowledge in most evaluation perspectives, while it actually suffers from the factuality issue as expected.\"\n",
      "\n",
      "2. **질문 :** LLM의 매개변수에 인코딩된 지식에 대한 광범위한 연구가 진행되었다 [36, 40].\n",
      "   - **답변 :** LLM의 매개변수에 인코딩된 지식에 대한 연구는 LLM이 생성하는 지식의 질과 신뢰성을 평가하는 데 중요한 역할을 합니다. 연구 결과, LLM이 생성한 지식은 정보 검색 모델보다 더 유용하고 관련성이 높지만, 사실성 문제는 여전히 존재합니다. \n",
      "   - **근거 :** \"Despite obtaining lower factuality than retrieved knowledge, generated knowledge contributes more to the factuality of downstream tasks.\"\n",
      "\n",
      "답변 요약 \n",
      ": 최근 연구들은 대형 언어 모델(LLM)이 사전 훈련 데이터에서 상당한 사실적 지식을 포착할 수 있는 능력을 보여주고 있으며, LLM이 생성한 지식은 정보 검색 기술보다 더 나은 성능을 발휘합니다. LLM의 매개변수에 인코딩된 지식에 대한 연구는 LLM이 생성하는 지식의 질과 신뢰성을 평가하는 데 중요한 역할을 하며, 생성된 지식은 하위 작업에서 더 유용하고 관련성이 높지만 사실성 문제는 여전히 존재합니다. 이러한 연구 결과는 LLM을 지식 생성기로 활용하는 데 있어 중요한 통찰을 제공합니다.\n",
      "\n",
      "인용 논문 제목 (Title): Language models as knowledge bases?\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)이 사전 훈련 데이터에서 사실적 지식을 어떻게 획득하는지를 심층적으로 분석함으로써, LLM의 지식 생성 능력에 대한 기존 연구를 발전시켰습니다. 특히, LLM이 정보 검색 기술보다 더 나은 성능을 발휘하는 이유를 설명하고, 지식의 질과 신뢰성을 평가하는 데 중요한 요소인 사실성 문제를 다루었습니다. 또한, LLM의 매개변수에 인코딩된 지식의 동적 변화를 분석하여, 지식의 획득과 망각 과정이 LLM의 성능에 미치는 영향을 규명함으로써, LLM을 지식 생성기로 활용하는 데 있어 중요한 통찰을 제공합니다. 이러한 연구는 LLM의 훈련 및 활용 방안을 개선하는 데 기여할 것으로 기대됩니다.\n",
      "####\n",
      "인용 논문 제목 (Title): Extracting training data from large language models\n",
      "\n",
      "1. **질문 :** 모델은 모든 획득 깊이에서 로그 확률의 더 큰 개선을 보이지만, 잊어버리는 속도가 더 빠르며, 결국 훈련 종료 시점(t = 2000)에서 패러프레이즈 주입 시나리오와 유사한 수준의 개선을 초래한다.  \n",
      "   - **답변 :** 모델은 훈련 과정에서 로그 확률이 더 크게 개선되지만, 잊어버리는 속도가 빨라 결국 훈련 종료 시점에서 패러프레이즈 주입 시나리오와 비슷한 개선 수준에 도달한다. 이는 모델이 훈련 데이터의 특정 예제를 기억하는 데 한계가 있음을 나타낸다.  \n",
      "   - **근거 :** \"the forgetting is faster, eventually resulting in a similar level of improvement at the end of the training (t = 2000) compared to the paraphrase injection scenario.\"\n",
      "\n",
      "2. **질문 :** 그림 5의 추정된 x-절편은 훈련을 통해 획득한 사실적 지식의 완전한 손실로 이어질 추가 훈련 토큰의 수를 나타낸다.  \n",
      "   - **답변 :** 그림 5의 x-절편은 모델이 훈련 데이터에서 기억한 사실적 지식이 완전히 소실되기 위해 필요한 추가 훈련 토큰의 수를 나타낸다. 이는 모델의 기억력과 관련된 중요한 지표로, 특정 예제가 얼마나 자주 등장하는지가 메모리 유지에 영향을 미친다.  \n",
      "   - **근거 :** \"the estimated x-intercepts in Figure 5 represent the number of additional training tokens that would lead to the complete loss of the factual knowledge acquired by training.\"\n",
      "\n",
      "3. **질문 :** 중복되지 않은 데이터와 더 큰 배치 크기로 LLM을 사전 훈련하면 사실적 지식의 습득이 향상되어 학습한 사실적 지식을 잊어버리는 것에 대해 더 강력해진다.  \n",
      "   - **답변 :** 중복되지 않은 데이터와 더 큰 배치 크기로 LLM을 사전 훈련하면 모델이 사실적 지식을 더 잘 습득하게 되어, 학습한 지식을 잊어버리는 데 더 강력해진다. 이는 모델의 일반화 능력을 향상시키고, 훈련 데이터의 다양성을 높이는 데 기여한다.  \n",
      "   - **근거 :** \"Pretraining LLMs with deduplicated data and larger batch sizes enhances the acquisition of factual knowledge, making them more robust against forgetting the learned factual knowledge.\"\n",
      "\n",
      "답변 요약: 이 논문은 대형 언어 모델이 훈련 데이터에서 개별 예제를 기억하고 이를 추출할 수 있는 가능성을 보여준다. 모델은 로그 확률의 개선을 보이지만, 잊어버리는 속도가 빨라 결국 비슷한 수준의 개선에 도달한다. 그림 5의 x-절편은 훈련을 통해 습득한 사실적 지식의 손실에 필요한 추가 훈련 토큰 수를 나타내며, 중복되지 않은 데이터와 큰 배치 크기로 사전 훈련된 LLM은 사실적 지식의 습득을 향상시켜 잊어버리는 것에 대해 더 강력해진다. 이러한 결과는 대형 언어 모델의 훈련 및 메모리 유지에 대한 중요한 통찰을 제공하며, 향후 연구에서 메모리와 관련된 문제를 해결하기 위한 다양한 접근법이 필요함을 시사한다.\n",
      "\n",
      "인용 논문 제목 (Title): Extracting training data from large language models\n",
      "\n",
      "해당 논문은 대형 언어 모델이 훈련 과정에서 사실적 지식을 어떻게 습득하고 잊어버리는지를 심층적으로 분석함으로써, 기존 연구에서 제기된 질문들에 대한 명확한 답변을 제시하였다. 특히, 모델이 훈련 데이터의 특정 예제를 기억하는 데 한계가 있음을 보여주며, 잊어버리는 속도가 빠르다는 점을 강조하였다. 또한, 중복되지 않은 데이터와 큰 배치 크기로 훈련할 경우 사실적 지식의 습득이 향상되고 잊어버림에 대한 저항력이 증가한다는 발견은, LLM의 훈련 및 메모리 유지에 대한 중요한 통찰을 제공하며, 향후 연구 방향에 대한 기초를 마련하였다.\n",
      "####\n",
      "인용 논문 제목 (Title): Large language models struggle to learn long-tail knowledge\n",
      "\n",
      "1. **질문 :** 긴 꼬리 지식을 습득하지 못하는 실패와 데이터셋 중복 제거의 중요성에 대해 설명해 주세요.\n",
      "   - **답변 :** 대형 언어 모델(LLM)은 인터넷에서 방대한 양의 정보를 학습하지만, 특정 정보는 드물게 나타나며 이러한 드문 정보, 즉 긴 꼬리 지식을 습득하는 데 어려움을 겪습니다. 데이터셋 중복 제거는 이러한 문제를 해결하는 데 중요한 역할을 하며, 모델이 다양한 정보를 학습할 수 있도록 돕습니다. 연구에 따르면, 모델의 성능은 사전 훈련 데이터에서 관련 문서의 수와 강한 상관관계를 보입니다.\n",
      "   - **근거 :** \"우리의 결과는 정확성과 관련 문서 수 간의 강한 상관관계와 인과 관계를 보여줍니다.\"\n",
      "\n",
      "2. **질문 :** 최근 LLM에 대한 연구에서 긴 꼬리 지식 습득이 저조하다는 사실이 밝혀졌습니다. 이에 대한 설명을 해주세요.\n",
      "   - **답변 :** 최근 연구에 따르면, LLM은 긴 꼬리 지식을 습득하는 데 어려움을 겪고 있으며, 이는 모델이 사전 훈련 데이터에서 자주 나타나는 정보에 의존하기 때문입니다. 모델의 크기가 커질수록 긴 꼬리 지식 학습 능력이 향상되지만, 현재의 모델은 긴 꼬리 질문에 대해 경쟁력 있는 성능을 내기 위해서는 수십 배의 규모로 확장해야 합니다.\n",
      "   - **근거 :** \"우리는 오늘날의 모델이 사전 훈련 데이터에서 지원이 적은 질문에 대해 경쟁력 있는 QA 성능을 달성하기 위해서는 수많은 배수로 확장해야 한다고 추정합니다.\"\n",
      "\n",
      "답변 요약 \n",
      ": 대형 언어 모델(LLM)은 방대한 양의 정보를 학습하지만, 드물게 나타나는 긴 꼬리 지식을 습득하는 데 어려움을 겪고 있습니다. 이는 모델이 사전 훈련 데이터에서 자주 나타나는 정보에 의존하기 때문이며, 데이터셋 중복 제거가 이러한 문제를 해결하는 데 중요한 역할을 합니다. 연구 결과, 모델의 성능은 관련 문서 수와 강한 상관관계를 보이며, 모델의 크기가 커질수록 긴 꼬리 지식 학습 능력이 향상되지만, 현재의 모델은 긴 꼬리 질문에 대해 경쟁력 있는 성능을 내기 위해서는 수십 배의 규모로 확장해야 합니다. 이러한 결과는 LLM의 지식 습득 방식과 관련된 중요한 통찰을 제공합니다.\n",
      "\n",
      "인용 논문 제목 (Title): Large language models struggle to learn long-tail knowledge\n",
      "\n",
      "해당 논문은 대형 언어 모델(LLM)이 긴 꼬리 지식을 습득하는 데 어려움을 겪는 이유를 데이터셋의 중복성과 관련하여 설명합니다. 이와 관련하여, 본 연구는 LLM의 사실적 지식 습득 메커니즘을 심층적으로 분석하여, 모델이 사전 훈련 데이터에서 자주 나타나는 정보에 의존하는 경향을 확인했습니다. 또한, 데이터 중복 제거가 모델의 성능 향상에 기여함을 보여주며, 모델 크기와 훈련 조건이 지식 습득에 미치는 영향을 규명했습니다. 이러한 통찰은 LLM의 지식 습득 방식에 대한 이해를 심화시키고, 긴 꼬리 지식 습득의 한계를 극복하기 위한 방향성을 제시합니다.\n",
      "####\n"
     ]
    }
   ],
   "source": [
    "for index in related_reference.keys():\n",
    "    print(related_reference[index]['Summary'])\n",
    "    print()\n",
    "    print(related_reference[index]['Summary_QnA'])\n",
    "    print(\"####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summary = \"\"\n",
    "for i, index in enumerate(related_reference.keys()):\n",
    "    reference_summary += f\"{i+1}번째\\n\"+ related_reference[index]['Summary'] + \"\\n\\n\" + related_reference[index]['Summary_QnA'] + \"####\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. 기본 정보\n",
      "1) 제목: How Do Large Language Models Acquire Factual Knowledge During Pretraining?\n",
      "2) 저자: Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo\n",
      "\n",
      "### 2. 연구 목적\n",
      "1) 문제의식: 대형 언어 모델의 사실적 지식 습득 메커니즘\n",
      "2) 설명: 최근 대형 언어 모델(LLM)이 상당한 사실적 지식을 저장할 수 있다는 관찰에도 불구하고, 이들이 사전 훈련 중 사실적 지식을 어떻게 습득하는지에 대한 이해는 제한적이다. 본 연구는 LLM의 사실적 지식 습득 과정을 분석하여, 훈련 데이터의 양, 훈련 단계, 모델 크기, 배치 크기 등의 다양한 조건이 지식 습득에 미치는 영향을 조사한다. 이를 통해 LLM의 훈련 동역학을 이해하고, 지식 습득의 메커니즘을 규명하고자 한다.\n",
      "\n",
      "### 3. 연구 방법\n",
      "1) 실험 방법: 연구진은 LLM의 중간 사전 훈련 체크포인트를 사용하여, 이전에 접하지 않은 목표 지식을 주입하고, 다양한 조건에서 사실적 지식의 습득 과정을 모니터링하였다. \n",
      "2) 데이터: FICTIONAL KNOWLEDGE 데이터셋을 구성하여, 허구적이지만 현실적인 개체에 대한 설명을 포함한 문장을 주입하였다. 이 데이터셋은 LLM이 훈련 중에 접하지 않은 지식을 포함한다.\n",
      "3) 모델 및 분석 방법: OLMo 모델을 사용하여, 주입된 지식에 대한 로그 확률을 평가하고, 지식 습득의 효과성 및 유지 가능성을 측정하기 위해 다양한 메트릭을 정의하였다.\n",
      "\n",
      "### 4. 주요 결과\n",
      "1) 연구의 주요 발견: LLM은 사실적 지식을 습득할 때, 미세한 확률의 누적을 통해 이루어지며, 훈련 중 지식이 주어지지 않으면 잊어버리는 경향이 있다. 또한, 모델 크기가 클수록 지식 습득의 효과성이 높아지지만, 훈련 데이터의 양이 많아져도 효과성은 크게 개선되지 않는다.\n",
      "2) 기여 및 성과: 본 연구는 LLM의 사실적 지식 습득 동역학을 세밀하게 분석하고, 데이터 중복 제거와 배치 크기 증가가 지식 습득에 긍정적인 영향을 미친다는 점을 밝혀내어, LLM의 훈련 방법론에 대한 새로운 통찰을 제공한다.\n",
      "\n",
      "### 5. 결론 및 시사점\n",
      "1) 결론: LLM의 사실적 지식 습득은 미세한 확률의 누적을 통해 이루어지며, 잊어버림 현상과의 관계가 중요하다. \n",
      "2) 시사점: 연구 결과는 LLM의 훈련 데이터 구성 및 훈련 방법에 대한 전략적 접근을 제안하며, LLM의 성능 향상에 기여할 수 있다.\n",
      "3) 연구의 한계: 본 연구는 특정 모델과 데이터셋에 국한되어 있으며, 다양한 LLM 아키텍처에 대한 일반화 가능성에 대한 검증이 필요하다.\n",
      "4) 향후 연구 방향: LLM의 지식 습득 메커니즘을 더욱 깊이 이해하기 위해, 다양한 유형의 지식과 훈련 조건을 탐색하는 추가 연구가 필요하다.\n"
     ]
    }
   ],
   "source": [
    "print(output['Basic_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
